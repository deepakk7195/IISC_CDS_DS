{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakk7195/IISC_CDS_DS/blob/Scalable_ML_GenAI/AST_08_LangChain_with_Open_Source_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment 8: Open Source LLMs with LangChain ü¶úüîó"
      ],
      "metadata": {
        "id": "RMNv0S7qBl1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* use open source LLMs: **zephyr-7b-beta**, **Mistral-7B-Instruct-v0.2** through HuggingFaceHub with LangChain\n",
        "* understand & use the concept of Prompt template, Memory and output parsers in LangChain\n"
      ],
      "metadata": {
        "id": "R7nOHNxJqC2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Steps:"
      ],
      "metadata": {
        "id": "rKQ0Fvl_jNqU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YzfoPvJDiTX"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoZJWGErxGf"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBPPuGmBlDIN",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M3_AST_08_LangChain_with_Open_Source_LLMs_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://cds-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps for Creating Hugging Face access tokens:\n",
        "\n",
        "* **Visit the Hugging Face Website:** Head to the Hugging Face website (https://huggingface.co/) to begin the account creation process.\n",
        "\n",
        "* **Click on ‚ÄúSign Up‚Äù:** Locate the ‚ÄúSign Up‚Äù button on the top right corner of the homepage and click on it.\n",
        "\n",
        "* **Choose a Sign-Up Method:** Hugging Face offers multiple sign-up methods, including Google, GitHub, and email. Select your preferred method and follow the prompts to complete the registration.\n",
        "\n",
        "* **Verify Your Email (if applicable):** If you choose to sign up via email, verify your email address by clicking on the confirmation link sent to your inbox.\n",
        "\n",
        "* **Complete Your Profile:** Enhance your Hugging Face experience by completing your profile. Add a profile picture, a short bio, and any other details you‚Äôd like to share with the community.\n",
        "\n",
        "* **Create Your Access Token:** Go to the link (https://huggingface.co/settings/tokens)\n",
        "\n",
        "* **Click on the option 'Access Tokens' from the left pane.**\n",
        "\n",
        "* **Then under the User Access Tokens, click on the button 'New token'.** The Hugging Face access token will be generated. Copy and paste the access token in your Google Colab Notebook."
      ],
      "metadata": {
        "id": "oNLGugJ1KW3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install required dependencies"
      ],
      "metadata": {
        "id": "WeXRnNMfnFqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Langchain\n",
        "!pip -q install langchain\n",
        "\n",
        "# Library to communicate with HF hub\n",
        "!pip -q install --upgrade huggingface_hub"
      ],
      "metadata": {
        "id": "aKLiNSv6wTr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required packages"
      ],
      "metadata": {
        "id": "T0sgU1wiq7Hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "u0IydGx_q78h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Provide your HuggingFace api key/access token**"
      ],
      "metadata": {
        "id": "dMBDqFT0kkgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your HuggingFace access token when prompted\n",
        "\n",
        "pass_token = getpass(\"Enter your HuggingFace access token: \")\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = pass_token\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = pass_token\n",
        "\n",
        "del pass_token"
      ],
      "metadata": {
        "id": "i9TSeu4cq1Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exploring Open Source LLMs hosted on HuggingFace**\n",
        "\n",
        ">**I.** HuggingFaceH4/zephyr-7b-beta\n",
        ">\n",
        ">**II.** mistralai/Mistral-7B-Instruct-v0.2\n",
        "\n",
        "[Langchain link](https://python.langchain.com/docs/integrations/chat/huggingface) for using Hugging Face LLM's as chat models."
      ],
      "metadata": {
        "id": "GgzDSiux-EuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **I.** [**HuggingFaceH4/zephyr-7b-beta**](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)"
      ],
      "metadata": {
        "id": "oVK3LSt6mzKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import HuggingFace model abstraction class from langchin\n",
        "from langchain_community.llms import HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "QudSou2y-T4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens = 512,\n",
        "    top_k = 30,\n",
        "    temperature = 0.1,\n",
        "    repetition_penalty = 1.03,\n",
        ")"
      ],
      "metadata": {
        "id": "jVRB1nztyTUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"How to learn programming? give 5 points\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "qrneNiybIFl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prompt Template**\n",
        "\n",
        "Prompt templates are predefined recipes for generating prompts for language models.\n",
        "\n",
        "A template may include instructions, few-shot examples, and specific context and questions appropriate for a given task.\n",
        "\n",
        "LangChain provides tooling to create and work with prompt templates.\n",
        "\n",
        "To know more about Prompt template, refer [here](https://python.langchain.com/docs/modules/model_io/prompts/quick_start)."
      ],
      "metadata": {
        "id": "F4N14UjkBaws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example-1**"
      ],
      "metadata": {
        "id": "-v-l3yx9hQs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"Tell me a {adjective} joke about {content}.\"\n",
        ")\n",
        "messages = prompt_template.format(adjective=\"funny\", content=\"Trump\")\n",
        "messages"
      ],
      "metadata": {
        "id": "NIjgIglFbjDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models.huggingface import ChatHuggingFace"
      ],
      "metadata": {
        "id": "9co7f7rZbjGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatHuggingFace(llm = llm)"
      ],
      "metadata": {
        "id": "t4t_QejvbjJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_model.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "DjM9t0INbjLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example-2**"
      ],
      "metadata": {
        "id": "ZPeo4FQBhL0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A brief explanation on langchain.schema\n",
        "\n",
        "LangChain Schema covers the basic data types and schemas that are used throughout the codebase. It comprises four primary elements: Text, ChatMessages, Examples, and Document.\n",
        "\n",
        "**<u>Text:</u>**\n",
        "\n",
        "When working with language models, the primary interface through which you can interact with them is through text. This is because a lot of models are essentially ‚Äútext in, text out‚Äù.\n",
        "\n",
        "Therefore, many of the interfaces in Langchain are centered around text.\n",
        "* Text is the primary mode of communication between the user and the AI system, and it is where the AI system receives input and provides output.\n",
        "\n",
        "**<u>ChatMessages:</u>**\n",
        "\n",
        "The ChatMessages schema facilitates seamless interaction between the user and the AI system through a conversational interface.\n",
        "\n",
        "As we know that the primary interface through which end users interact with the AI system is a chat interface, hence, some model providers even started providing access to the underlying API in a way that expects chat messages.\n",
        "\n",
        "* These messages have a content field (which is usually text) and are associated with a user. Currently, the supported users are System, Human, and AI.\n",
        "* SystemChatMessage - A chat message representing information that should be instructions to the AI system.\n",
        "* HumanChatMessage - A chat message representing information coming from a human interacting with the AI system.\n",
        "* AIChatMessage - A chat message representing information coming from the AI system.\n",
        "\n",
        "**<u>Examples:</u>**\n",
        "\n",
        "The Examples schema plays a critical role in refining the AI system‚Äôs performance. By providing the system with examples of correct input-output pairs, the system learns to produce the correct output for a given input.\n",
        "* Examples are input/output pairs that represent inputs to a function and the expected output.\n",
        "* They can be used in both training and evaluation of models.\n",
        "* This is a fundamental part of the training process for AI systems, and it‚Äôs also essential for evaluating the system‚Äôs performance.\n",
        "\n",
        "**<u>Document:</u>**\n",
        "\n",
        "It consists of page_content (the content of the data) and metadata (auxiliary pieces of information describing attributes of the data).\n",
        "\n",
        "The Document schema enables the AI system to process and analyze unstructured data, which is a significant part of the data available in the real world. By understanding and making sense of unstructured data, AI systems can derive meaningful insights and make more accurate predictions.\n",
        "\n",
        "* This is a Class for storing a piece of text and associated metadata.\n",
        "* It creates a new model by parsing and validating input data from keyword arguments.\n",
        "* langchain.schema.document.Document raises ValidationError if the input data cannot be parsed to form a valid model."
      ],
      "metadata": {
        "id": "1Jkm9uSQKRO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import (\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        ")"
      ],
      "metadata": {
        "id": "bat0JTd7GrJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"Tell me {count} facts about {event_or_place}.\"\n",
        ")\n",
        "user_msg = prompt_template.format(count=5, event_or_place=\"Tajmahal\")\n",
        "user_msg"
      ],
      "metadata": {
        "id": "mQe8qxghewsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You're a knowledgeable historian\"),\n",
        "    HumanMessage(content=user_msg),\n",
        "]"
      ],
      "metadata": {
        "id": "GdGDCoQhmuDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models.huggingface import ChatHuggingFace"
      ],
      "metadata": {
        "id": "vCpfJTPCAqGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "9kg1GDWsCRbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model.model_id"
      ],
      "metadata": {
        "id": "27Iyhp-5DJ5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model._to_chat_prompt(messages)"
      ],
      "metadata": {
        "id": "9niBkmKIDMVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_model.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "ZduaUIkl-VpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example-3**\n",
        "\n",
        "The prompt to *chat models* is a list of chat messages.\n",
        "\n",
        "Each chat message is associated with content, and an additional parameter called `role`. For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role."
      ],
      "metadata": {
        "id": "USL19U5MKapo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "jsZWlMZEEcth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful A {persona}.\"),\n",
        "        (\"human\", \"Hello, how are you doing?\"),\n",
        "        (\"ai\", \"I'm doing well, thanks!\"),\n",
        "        (\"human\", \"{user_input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "TBLyJ-sFk8Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persona = \"\"\"trustworthy friend\"\"\"\n",
        "query= \"\"\"\n",
        "I am not able to understand the concept taught in class. \\\n",
        "Could you please suggest something? \\\n",
        "I need your help. Give 5 points to work on.\n",
        "\"\"\"\n",
        "messages = chat_template.format_messages(persona = persona, user_input=query)"
      ],
      "metadata": {
        "id": "1rr0S0bklaIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "id": "XoEgU1O5LlK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model._to_chat_prompt(messages)"
      ],
      "metadata": {
        "id": "aP9IQ7q8mYu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_model.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "xVCqtycfL7fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output Parsers**\n",
        "\n",
        "Let's start with defining how we would like the LLM output to look like:"
      ],
      "metadata": {
        "id": "7BPY4s_hGQv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An example output format\n",
        "{\n",
        "  \"gift\": False,\n",
        "  \"delivery_days\": 5,\n",
        "  \"price_value\": \"pretty affordable!\"\n",
        "}"
      ],
      "metadata": {
        "id": "x1nyuc_1GO6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_review = \"\"\"\\\n",
        "This leaf blower is pretty amazing.  It has four settings:\\\n",
        "candle blower, gentle breeze, windy city, and tornado. \\\n",
        "It arrived in two days, just in time for my wife's \\\n",
        "anniversary present. \\\n",
        "I think my wife liked it so much she was speechless. \\\n",
        "So far I've been the only one using it, and I've been \\\n",
        "using it every other morning to clear the leaves on our lawn. \\\n",
        "It's slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qW37-qdYGaOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift or present for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ppJOtjsEGdL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating prompt template\n",
        "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
        "print(prompt_template)"
      ],
      "metadata": {
        "id": "gQDimFP3Gp5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = prompt_template.format_messages(text=customer_review)\n",
        "response = chat_model.invoke(messages)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "id": "MYur071rMz6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(response.content))"
      ],
      "metadata": {
        "id": "cV1eVBvyHhfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Parse the LLM output string into a Python dictionary**\n",
        "\n",
        "[Structured output parser](https://python.langchain.com/docs/modules/model_io/output_parsers/types/structured)\n"
      ],
      "metadata": {
        "id": "B3IzTQ5VH5gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser"
      ],
      "metadata": {
        "id": "GCLCLsEDH8ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gift_schema = ResponseSchema(name=\"gift\",\n",
        "                             description=\"Was the item purchased\\\n",
        "                             as a gift for someone else? \\\n",
        "                             Answer True if yes,\\\n",
        "                             False if not or unknown.\")"
      ],
      "metadata": {
        "id": "M21TRubyIApT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
        "                                      description=\"How many days\\\n",
        "                                      did it take for the product\\\n",
        "                                      to arrive? If this \\\n",
        "                                      information is not found,\\\n",
        "                                      output -1.\")"
      ],
      "metadata": {
        "id": "ERIgDcxPIDwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_value_schema = ResponseSchema(name=\"price_value\",\n",
        "                                    description=\"Extract any\\\n",
        "                                    sentences about the value or \\\n",
        "                                    price, and output them as a \\\n",
        "                                    comma separated Python list.\")"
      ],
      "metadata": {
        "id": "mA-M0G-jIGvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_schemas = [gift_schema,\n",
        "                    delivery_days_schema,\n",
        "                    price_value_schema]"
      ],
      "metadata": {
        "id": "CvSJtOAFIHrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ],
      "metadata": {
        "id": "ygvBJzgNIMXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_instructions = output_parser.get_format_instructions()"
      ],
      "metadata": {
        "id": "9g1lDzdBIPeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(format_instructions)"
      ],
      "metadata": {
        "id": "B1gh72vONJAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using above format instructions in msg definition after prompt**"
      ],
      "metadata": {
        "id": "UkI-yoDOJB_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_template_N = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product\\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "text: {text}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zyMcRQQ0Jp2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template = review_template_N)\n",
        "\n",
        "messages = prompt.format_messages(text = customer_review,\n",
        "                                  format_instructions = format_instructions)"
      ],
      "metadata": {
        "id": "FD-kiFv8Icgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(messages[0].content)"
      ],
      "metadata": {
        "id": "xnNRC-_yJet1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_model.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "_2lb6YGNJ6so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict = output_parser.parse(response.content)\n",
        "output_dict"
      ],
      "metadata": {
        "id": "6TWJ8VioKMAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(output_dict)"
      ],
      "metadata": {
        "id": "GMwbAx7jKWJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict.get('delivery_days')"
      ],
      "metadata": {
        "id": "y_ED1nYBKYwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [**Customizing Conversational Memory**](https://python.langchain.com/docs/modules/memory/conversational_customization)\n",
        "\n",
        "\n",
        "#### **LangChain: Memory**\n",
        "\n",
        "LangChain can helps in building better chatbots, or have\n",
        "an LLM with more effective chats by better managing\n",
        "what it remembers from the conversation you've had so far.\n",
        "\n",
        "* [ConversationBufferMemory](https://python.langchain.com/docs/modules/memory/types/buffer)\n",
        "* [ConversationBufferWindowMemory](https://python.langchain.com/docs/modules/memory/types/buffer_window)\n",
        "* [ConversationTokenBufferMemory](https://python.langchain.com/docs/modules/memory/types/token_buffer)\n",
        "* [ConversationSummaryMemory](https://python.langchain.com/docs/modules/memory/types/summary)"
      ],
      "metadata": {
        "id": "Br30bwaPKs0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ConversationBufferMemory**"
      ],
      "metadata": {
        "id": "yeF_7V2wLAGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "vq5TYaYMKzTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(\n",
        "    llm=chat_model,\n",
        "    memory = memory,\n",
        "    verbose=True # False\n",
        ")"
      ],
      "metadata": {
        "id": "6_tIOuz_K9JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi, I am John\")"
      ],
      "metadata": {
        "id": "k1tpxowSLRJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What is 6 divided by 2?\")"
      ],
      "metadata": {
        "id": "opaSTtaZLcr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Do you remember my name from previous conversation?\")"
      ],
      "metadata": {
        "id": "L-7jfhb2LwGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **II. mistralai/Mistral-7B-Instruct-v0.2**\n"
      ],
      "metadata": {
        "id": "zSbCSUOfxXa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "h_733Aai1RG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How to learn programing? Give 5 examples. \""
      ],
      "metadata": {
        "id": "_XZllnjBzqw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "model_kwargs={\"max_length\": 128, \"token\": os.environ[\"HF_TOKEN\"]}\n",
        "\n",
        "llm = HuggingFaceEndpoint(repo_id=repo_id,\n",
        "                          temperature=0.5,\n",
        "                          model_kwargs= model_kwargs)"
      ],
      "metadata": {
        "id": "YOQFkpas0vl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(question)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "bXJMBgfy0A5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prompt Template**\n",
        "\n",
        "**Example-1**"
      ],
      "metadata": {
        "id": "OmRI-p9fp0SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import (\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        ")"
      ],
      "metadata": {
        "id": "xiZNTCsGNpPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "WnF-Qc_FrTZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_s = \"\"\"You are a {style1}.\\\n",
        "Tell me  {count} facts about {event_or_place}.```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SHJWqMg3yxa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(template_s)"
      ],
      "metadata": {
        "id": "wHucwPZ7yVPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages[0].prompt"
      ],
      "metadata": {
        "id": "jH_lqJRbzaHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages[0].prompt.input_variables"
      ],
      "metadata": {
        "id": "fDyBeGD8zej9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_messages = prompt_template.format_messages(\n",
        "                    style1=\"knowledgeable historian\",\n",
        "                    count=5,\n",
        "                    event_or_place=\"Tajmahal\")"
      ],
      "metadata": {
        "id": "QXUiH0sszkUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_messages"
      ],
      "metadata": {
        "id": "qP62G5bz0KBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "Access to model **mistralai/Mistral-7B-Instruct-v0.2** is restricted and you are not in the authorized list. In the following code cell, you are trying to access the model from a gated repository. So, it will throw an error.\n",
        "\n",
        "To resolve this issue, you can follow these steps:\n",
        "\n",
        "**Step-1:** Visit the model page on the Hugging Face website:\n",
        "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2 and request for access.\n",
        "\n",
        "**Step-2:** Wait for the repository owner to grant you access. Once access is granted, you'll receive an email notification.\n",
        "\n",
        "**Step-3:** After receiving access, you can use the model in your code without encountering the 403 error.\n",
        "\n",
        "* Until you receive access, you won't be able to use the model in your code. Once you have access, you can try running the code again, and it should work without any errors."
      ],
      "metadata": {
        "id": "DC9EqaLGM765"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
        "\n",
        "chat_model = ChatHuggingFace(llm=llm)\n",
        "\n",
        "chat_model.model_id"
      ],
      "metadata": {
        "id": "K8BIeBKVx2xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model._to_chat_prompt(user_messages)"
      ],
      "metadata": {
        "id": "ybxEq_9JqywX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_model.invoke(user_messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "SYI0aD8Hsty_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example-2**"
      ],
      "metadata": {
        "id": "wakjVUVZp2YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"How to learn programming? give 5 points\")]"
      ],
      "metadata": {
        "id": "jiFDpiyENyOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "Access to model **mistralai/Mistral-7B-Instruct-v0.2** is restricted and you are not in the authorized list. In the following code cell, you are trying to access the model from a gated repository. So, it will throw an error.\n",
        "\n",
        "To resolve this issue, you can follow these steps:\n",
        "\n",
        "**Step-1:** Visit the model page on the Hugging Face website:\n",
        "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2 and request for access.\n",
        "\n",
        "**Step-2:** Wait for the repository owner to grant you access. Once access is granted, you'll receive an email notification.\n",
        "\n",
        "**Step-3:** After receiving access, you can use the model in your code without encountering the 403 error.\n",
        "\n",
        "* Until you receive access, you won't be able to use the model in your code. Once you have access, you can try running the code again, and it should work without any errors."
      ],
      "metadata": {
        "id": "WlJO1WOASLRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
        "\n",
        "chat_model = ChatHuggingFace(llm=llm)\n",
        "\n",
        "chat_model.model_id"
      ],
      "metadata": {
        "id": "q71mv_vAxzk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model._to_chat_prompt(messages)"
      ],
      "metadata": {
        "id": "6SO2qIrju7rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_model.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "jEhKW2msODT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErjQyyi4nR2n"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "source": [
        "#@title Which of the following prompt techniques in LangChain allows flexible templated prompts that are suitable for better describing the role and content? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\", \"PromptTemplate\", \"ChatPromptTemplate\", \"Both\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}