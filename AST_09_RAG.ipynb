{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "efb6b5aec3cc4a7aa0609e42ccb3aa64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46ceb8e3a7af464a82bcbcf78459cc8a",
              "IPY_MODEL_550b9df56cee4f988e3fe3ab747896e7",
              "IPY_MODEL_656fd737fc7c4e9797932943537f7c45"
            ],
            "layout": "IPY_MODEL_7283ad4e7e9a4569ae85810bcfb0650c"
          }
        },
        "46ceb8e3a7af464a82bcbcf78459cc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158291693e4340f7a57f7e9de651b6ac",
            "placeholder": "​",
            "style": "IPY_MODEL_0792045f9de248ba84dc1e25d6387efd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "550b9df56cee4f988e3fe3ab747896e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1b34dbabfe4d33900f07445faae468",
            "max": 1431,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7965d94feca74cc68f655d9b6fe64727",
            "value": 1431
          }
        },
        "656fd737fc7c4e9797932943537f7c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c0b2dd81c445e994b1ecd12dbcbdb4",
            "placeholder": "​",
            "style": "IPY_MODEL_7913fd12392749aba6a01b9e05a6445f",
            "value": " 1.43k/1.43k [00:00&lt;00:00, 50.2kB/s]"
          }
        },
        "7283ad4e7e9a4569ae85810bcfb0650c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158291693e4340f7a57f7e9de651b6ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0792045f9de248ba84dc1e25d6387efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e1b34dbabfe4d33900f07445faae468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7965d94feca74cc68f655d9b6fe64727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7c0b2dd81c445e994b1ecd12dbcbdb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7913fd12392749aba6a01b9e05a6445f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6988e3c3a54b4734a9d25febce22a5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57475090993c4e888b386aa7217a9b56",
              "IPY_MODEL_6e223cfefc664945bd442ee574ec2ffc",
              "IPY_MODEL_ea0b78f05c9048bb88574954bdce0842"
            ],
            "layout": "IPY_MODEL_683cd2017cd842a8a2b6f7873037f092"
          }
        },
        "57475090993c4e888b386aa7217a9b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50432d5640014a04bafeff0f66ba890b",
            "placeholder": "​",
            "style": "IPY_MODEL_58e7365ab1cf4bc3ba77649e27f74675",
            "value": "tokenizer.model: 100%"
          }
        },
        "6e223cfefc664945bd442ee574ec2ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d55b8d5b2e3d4263a9452ea79d3cf545",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d62ab39fb9f449784d662cbb138ca55",
            "value": 493443
          }
        },
        "ea0b78f05c9048bb88574954bdce0842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78b8e8779cf34a8eb2194d708ed5f462",
            "placeholder": "​",
            "style": "IPY_MODEL_9e189e1f3ae94e1984fe7487753218b8",
            "value": " 493k/493k [00:00&lt;00:00, 5.44MB/s]"
          }
        },
        "683cd2017cd842a8a2b6f7873037f092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50432d5640014a04bafeff0f66ba890b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e7365ab1cf4bc3ba77649e27f74675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55b8d5b2e3d4263a9452ea79d3cf545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d62ab39fb9f449784d662cbb138ca55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78b8e8779cf34a8eb2194d708ed5f462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e189e1f3ae94e1984fe7487753218b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4099ce9977024fccbd54c9438cac0fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c4ac7c44d28411cad0328ea2d38b6df",
              "IPY_MODEL_8a3b37ea16254459b2977836302b5b82",
              "IPY_MODEL_b2e82ad6dbc94460b20434051a4c7d01"
            ],
            "layout": "IPY_MODEL_381c71520a5c4b09bcdec5fa2799f61f"
          }
        },
        "5c4ac7c44d28411cad0328ea2d38b6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bf34591f43e4a18bb6070584e574fba",
            "placeholder": "​",
            "style": "IPY_MODEL_e228046479fb4aa89e6ca488a48d0d48",
            "value": "tokenizer.json: 100%"
          }
        },
        "8a3b37ea16254459b2977836302b5b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9d59258de684859bfcd43792725b5d6",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1bd782005cf423d83af90929f514ddd",
            "value": 1795303
          }
        },
        "b2e82ad6dbc94460b20434051a4c7d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2c6155cf8654752aae3d771de021a54",
            "placeholder": "​",
            "style": "IPY_MODEL_d5acd81c82e9435eb5a54cefe49ccc17",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 6.41MB/s]"
          }
        },
        "381c71520a5c4b09bcdec5fa2799f61f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bf34591f43e4a18bb6070584e574fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e228046479fb4aa89e6ca488a48d0d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d59258de684859bfcd43792725b5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1bd782005cf423d83af90929f514ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2c6155cf8654752aae3d771de021a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5acd81c82e9435eb5a54cefe49ccc17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e33df6577ea34e0f87479e1a4c157372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1954155914b8436ab9c6fb7cb55aea6c",
              "IPY_MODEL_cf99fc19b3a34524b9b232f53914eb8b",
              "IPY_MODEL_53bb1c76546f44ed9a1fa684540ebcfa"
            ],
            "layout": "IPY_MODEL_682fc224254b4705a7a3a968996d86ab"
          }
        },
        "1954155914b8436ab9c6fb7cb55aea6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91585cb397d476eb05f3a510751d1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_39bfb88b23f24f128c5f739072d5eca7",
            "value": "added_tokens.json: 100%"
          }
        },
        "cf99fc19b3a34524b9b232f53914eb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c6aedda9084ef199bec7a0a3c5d9a9",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12248540fabd4bfd89295f7f5371ce6a",
            "value": 42
          }
        },
        "53bb1c76546f44ed9a1fa684540ebcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8cb5374d98b449db1728e339ad0959d",
            "placeholder": "​",
            "style": "IPY_MODEL_d7d3afab4f6f475e822217d5aca18865",
            "value": " 42.0/42.0 [00:00&lt;00:00, 2.55kB/s]"
          }
        },
        "682fc224254b4705a7a3a968996d86ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b91585cb397d476eb05f3a510751d1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39bfb88b23f24f128c5f739072d5eca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c6aedda9084ef199bec7a0a3c5d9a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12248540fabd4bfd89295f7f5371ce6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8cb5374d98b449db1728e339ad0959d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d3afab4f6f475e822217d5aca18865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "437f3f7d6cc84e8facee3c33a8f2a600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf80c5ada22e4fd0bba8efe5c95c1470",
              "IPY_MODEL_6ab0967225ff40929ea9f5440fffe444",
              "IPY_MODEL_56826c3e2fa647968207982c9d6b0d49"
            ],
            "layout": "IPY_MODEL_80a0277d919e4d20ad1907ce561fc537"
          }
        },
        "cf80c5ada22e4fd0bba8efe5c95c1470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc4f3f671fa4ced830cd6ce44da599e",
            "placeholder": "​",
            "style": "IPY_MODEL_5412a815f46b4cba9bc9dcbeacd25521",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6ab0967225ff40929ea9f5440fffe444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e4e45ef2ac549e5b21817e122d22a7a",
            "max": 168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11e86fcb4b55431f9c2dc4d1f5809738",
            "value": 168
          }
        },
        "56826c3e2fa647968207982c9d6b0d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e04b9395d09d4bb19422031004555f4e",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8a9a0c402f4de2945d9789295350fe",
            "value": " 168/168 [00:00&lt;00:00, 12.9kB/s]"
          }
        },
        "80a0277d919e4d20ad1907ce561fc537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc4f3f671fa4ced830cd6ce44da599e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5412a815f46b4cba9bc9dcbeacd25521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e4e45ef2ac549e5b21817e122d22a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e86fcb4b55431f9c2dc4d1f5809738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e04b9395d09d4bb19422031004555f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8a9a0c402f4de2945d9789295350fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "168dfd421eea407c9c7f1bfe2be3cfdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adf005e74ac04b2d83d2df0a62b70ff5",
              "IPY_MODEL_b29424c42ab94fc8a6cad271a8d37126",
              "IPY_MODEL_7dae1bf764ce447bb5ce4866414aa6b8"
            ],
            "layout": "IPY_MODEL_cce7611142a94e29817d0617ae16f665"
          }
        },
        "adf005e74ac04b2d83d2df0a62b70ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_507b8e2cb5dd4bc1ac565ddd69377f21",
            "placeholder": "​",
            "style": "IPY_MODEL_b8941e11416e4f81b457aadd82dc96ad",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b29424c42ab94fc8a6cad271a8d37126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c17cb06e2407454cadd0dec084e2a9a1",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d8b801ebcd74cbaa9d5084305b04de4",
            "value": 26
          }
        },
        "7dae1bf764ce447bb5ce4866414aa6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21d006e0e6c402cae4fb45927e43d06",
            "placeholder": "​",
            "style": "IPY_MODEL_bb8b62791e0a41d0a6705bb398880031",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.90kB/s]"
          }
        },
        "cce7611142a94e29817d0617ae16f665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "507b8e2cb5dd4bc1ac565ddd69377f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8941e11416e4f81b457aadd82dc96ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c17cb06e2407454cadd0dec084e2a9a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8b801ebcd74cbaa9d5084305b04de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21d006e0e6c402cae4fb45927e43d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8b62791e0a41d0a6705bb398880031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa09140392c1424795ddab5c928773da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c5e4ced524e4e6684cadc8ea0b07a82",
              "IPY_MODEL_ddbc8e63333a4595913a38296bb8a209",
              "IPY_MODEL_877c7f7308e749548a03f9d9aaa856ff"
            ],
            "layout": "IPY_MODEL_252d33ff9cf241439b1d561a5dcb082b"
          }
        },
        "1c5e4ced524e4e6684cadc8ea0b07a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7124d707f64347ef85d06c3ebdf65588",
            "placeholder": "​",
            "style": "IPY_MODEL_eabf89b1a181408892e0575eee3300ec",
            "value": "vocab.json: 100%"
          }
        },
        "ddbc8e63333a4595913a38296bb8a209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_059d786237bd4922955e2b1859b61ef4",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eeb638e7de6944578aac2534e10e5c5a",
            "value": 1042301
          }
        },
        "877c7f7308e749548a03f9d9aaa856ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d84a9e95c2e4fbbb7be9d1b2ad56786",
            "placeholder": "​",
            "style": "IPY_MODEL_c7dd39aa66524b88b66ba192a6cbf56a",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.12MB/s]"
          }
        },
        "252d33ff9cf241439b1d561a5dcb082b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7124d707f64347ef85d06c3ebdf65588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eabf89b1a181408892e0575eee3300ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "059d786237bd4922955e2b1859b61ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb638e7de6944578aac2534e10e5c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d84a9e95c2e4fbbb7be9d1b2ad56786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7dd39aa66524b88b66ba192a6cbf56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cb60f5a000542df8e769d81d344af09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5edcc5167484ed39510bd5446fe41c4",
              "IPY_MODEL_00adbaea4c8141a69431d89f3910db2f",
              "IPY_MODEL_8381713bacdd46d0bba2d23e8cee3e6c"
            ],
            "layout": "IPY_MODEL_2881590b078449a2ab5b4c7752dc65b7"
          }
        },
        "d5edcc5167484ed39510bd5446fe41c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0f680f42bfc4a6da5d10fe7e806b7d9",
            "placeholder": "​",
            "style": "IPY_MODEL_250bdc9acaab4cc4ad0bc08325c31125",
            "value": "merges.txt: 100%"
          }
        },
        "00adbaea4c8141a69431d89f3910db2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eabf85e818247d08f9f4ef3d5e853b2",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af61a69ddf094c8881e0cd8161ed5aef",
            "value": 456318
          }
        },
        "8381713bacdd46d0bba2d23e8cee3e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba12b8a42bf84bba88ba297fb0b6ed59",
            "placeholder": "​",
            "style": "IPY_MODEL_f493159e719b41d69594c8466de58487",
            "value": " 456k/456k [00:00&lt;00:00, 2.94MB/s]"
          }
        },
        "2881590b078449a2ab5b4c7752dc65b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0f680f42bfc4a6da5d10fe7e806b7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250bdc9acaab4cc4ad0bc08325c31125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eabf85e818247d08f9f4ef3d5e853b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af61a69ddf094c8881e0cd8161ed5aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba12b8a42bf84bba88ba297fb0b6ed59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f493159e719b41d69594c8466de58487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2a4a66e9b994a7f9d6746d0e6de8018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0aff2f8421bf40c891306ade5bfe8fa7",
              "IPY_MODEL_06b759ce975542d2a267afd3be9b1a94",
              "IPY_MODEL_e8ee60a8e87b4e438ca37f9521cecbd6"
            ],
            "layout": "IPY_MODEL_8506aa13ceb345518783bbca90b5826d"
          }
        },
        "0aff2f8421bf40c891306ade5bfe8fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec88f1a00f1b4e53b708c526d4d1d6f5",
            "placeholder": "​",
            "style": "IPY_MODEL_86701fec82b04f49b3a5868c376cd6f5",
            "value": "tokenizer.json: 100%"
          }
        },
        "06b759ce975542d2a267afd3be9b1a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d7758e6124429c96208e0b972836b9",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c02da4a954c4da5bbee1acf51dca6bb",
            "value": 1355256
          }
        },
        "e8ee60a8e87b4e438ca37f9521cecbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c36ab6636d745bebc9006337dbfdec7",
            "placeholder": "​",
            "style": "IPY_MODEL_5d900242ffc0435db248dfec5f57c2aa",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.14MB/s]"
          }
        },
        "8506aa13ceb345518783bbca90b5826d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec88f1a00f1b4e53b708c526d4d1d6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86701fec82b04f49b3a5868c376cd6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33d7758e6124429c96208e0b972836b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c02da4a954c4da5bbee1acf51dca6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c36ab6636d745bebc9006337dbfdec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d900242ffc0435db248dfec5f57c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "200f17dc2a3b41a7bc22a12c4dee0516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a46860a31ae435ca9d4d2de69615bb0",
              "IPY_MODEL_c2b94e0068474f7bae36f68d7dbdd397",
              "IPY_MODEL_0b70fceff53144e8a51e076db6ac9234"
            ],
            "layout": "IPY_MODEL_88b3559a973548cda34622df3ee0acab"
          }
        },
        "7a46860a31ae435ca9d4d2de69615bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd7501eca90b41d0a0eac8325caf4aed",
            "placeholder": "​",
            "style": "IPY_MODEL_2aba1148f4f54386b9078d275ca50e03",
            "value": "config.json: 100%"
          }
        },
        "c2b94e0068474f7bae36f68d7dbdd397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcf6c53ad2874f2f9e15ab3b8128a8bf",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fafd6d9cd6a47ddb67920b8a0f0375b",
            "value": 665
          }
        },
        "0b70fceff53144e8a51e076db6ac9234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fc2a9ae189d4de099f4aa1d5c3b5870",
            "placeholder": "​",
            "style": "IPY_MODEL_6ad1e22dd3344880b3993b9e25cc02ec",
            "value": " 665/665 [00:00&lt;00:00, 46.2kB/s]"
          }
        },
        "88b3559a973548cda34622df3ee0acab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7501eca90b41d0a0eac8325caf4aed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aba1148f4f54386b9078d275ca50e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf6c53ad2874f2f9e15ab3b8128a8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fafd6d9cd6a47ddb67920b8a0f0375b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fc2a9ae189d4de099f4aa1d5c3b5870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad1e22dd3344880b3993b9e25cc02ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakk7195/IISC_CDS_DS/blob/Scalable_ML_GenAI/AST_09_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment 9: Retrieval Augmented Generation (RAG)  🦜🔗"
      ],
      "metadata": {
        "id": "1dCE5c5-F0C2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* **Understand the role of the Hugging Face API in natural language processing tasks:** You will learn how to use the Hugging Face API to access pre-trained language models, embeddings, and other NLP-related functionalities.\n",
        "\n",
        "* **Explore embeddings using the Hugging Face API:** You will learn how to use Hugging Face embeddings to represent text data in a vector space, enabling various NLP tasks such as similarity search and clustering.\n",
        "\n",
        "* **Perform information retrieval with maximum marginal relevance (MMR):** In this notebook, you will learn how to implement an information retrieval system using maximum marginal relevance (MMR) to retrieve relevant documents based on a given query.\n",
        "\n",
        "* **Generate text responses using a language model (LLM):** This notebook will give a fair idea how to use a Hugging Face language model (LLM) for text generation tasks, including setting parameters for maximum new tokens, top-k sampling, and temperature.\n",
        "\n",
        "* **Create a chatbot using a language model:** You will be able to integrate a Hugging Face language model into a chatbot application, enabling conversational interactions with users.\n",
        "\n",
        "* **Implement a retrieval-based question answering (QA) system:** You will be learning how to build a retrieval-based QA system using a combination of a language model and an information retrieval component.\n",
        "\n",
        "* **Understand and create RAG prompts:** This assignment will help you to construct prompts for **Retrieval Augmented Generation (RAG)** models, providing context and questions to generate informative and relevant responses.\n",
        "\n",
        "* **Apply learned concepts to real-world NLP tasks:** From this exercise, you will gain hands-on experience by applying the learned concepts to practical NLP tasks such as text generation, question answering, and chatbot development using the Hugging Face API.\n",
        "\n",
        "* **Use open source LLMs:** This notebook will show you the implementations through HuggingFaceHub with LangChain\n",
        "\n",
        "* **Implementing retrieval-based question answering:** In this experiemt, you will know how to create a retrieval-based question answering (QA) system using the **ConversationBufferMemory**\n"
      ],
      "metadata": {
        "id": "DlYrkCHCGcpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Steps:"
      ],
      "metadata": {
        "id": "KA-p1-3sL5v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2301931\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "DP-fpQe3L-HT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9665220904\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "HtDfTMzcMCdI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M3_AST_09_RAG_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx wget https://cdn.exec.talentsprint.com/static/cds/content/pca_d1.pdf\")\n",
        "    ipython.magic(\"sx wget https://cdn.exec.talentsprint.com/static/cds/content/ens_d2.pdf\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://cds-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "x3sy0UhOMIbx",
        "outputId": "cbdbae62-cc11-4848-bd18-ebeac7dc5e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2301931&recordId=5443\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps for Creating Hugging Face access tokens:\n",
        "\n",
        "* **Visit the Hugging Face Website:** Head to the Hugging Face website (https://huggingface.co/) to begin the account creation process.\n",
        "\n",
        "* **Click on “Sign Up”:** Locate the “Sign Up” button on the top right corner of the homepage and click on it.\n",
        "\n",
        "* **Choose a Sign-Up Method:** Hugging Face offers multiple sign-up methods, including Google, GitHub, and email. Select your preferred method and follow the prompts to complete the registration.\n",
        "\n",
        "* **Verify Your Email (if applicable):** If you choose to sign up via email, verify your email address by clicking on the confirmation link sent to your inbox.\n",
        "\n",
        "* **Complete Your Profile:** Enhance your Hugging Face experience by completing your profile. Add a profile picture, a short bio, and any other details you’d like to share with the community.\n",
        "\n",
        "* **Create Your Access Token:** Go to the link (https://huggingface.co/settings/tokens)\n",
        "\n",
        "* **Click on the option 'Access Tokens' from the left pane.**\n",
        "\n",
        "* **Then under the User Access Tokens, click on the button 'New token'.** The Hugging Face access token will be generated. Copy and paste the access token in your Google Colab Notebook."
      ],
      "metadata": {
        "id": "AwF6h4xHOyQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Installing and importing packages**"
      ],
      "metadata": {
        "id": "0ho6wusQn_ll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YmxD_RmDn0ju",
        "outputId": "7effd639-a7a9-4414-ab22-846c8109a556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchainhub\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20240521-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
            "Installing collected packages: types-requests, langchainhub\n",
            "Successfully installed langchainhub-0.1.15 types-requests-2.32.0.20240521\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface-hub\n",
        "!pip -q install langchain\n",
        "!pip -q install langchain_community\n",
        "!pip -q install pypdf\n",
        "!pip -q install chromadb\n",
        "!pip -q install tiktoken\n",
        "!pip install langchainhub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install the above packages and then Restart the runtime**"
      ],
      "metadata": {
        "id": "RrKn6XcQTIs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from getpass import getpass\n",
        "from langchain import hub\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceHubEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "1KQwtAysn8KC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Authentication for Hugging Face API**"
      ],
      "metadata": {
        "id": "5XF7eEn4oaUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hfapi_key = getpass(\"Enter you HuggingFace access token:\")\n",
        "os.environ[\"HF_TOKEN\"] = hfapi_key\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = hfapi_key"
      ],
      "metadata": {
        "id": "LDnEeTGr23Fg",
        "outputId": "aa5750d0-736e-4d3c-bfd7-ae5b009b7b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter you HuggingFace access token:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the documents**\n",
        "The PyPDFLoader class is to load text content from PDF documents into a format suitable for further analysis or processing. This class is a part of the langchain_community library.\n",
        "\n",
        "* The PyPDFLoader class contains methods for parsing PDF files and extracting text content from them.\n",
        "* It may handle various PDF file structures, including text, images, and tables, and extract text from them accordingly.\n",
        "* Additionally, it may handle cases where PDF documents contain multiple pages or complex formatting.\n",
        "\n",
        "[PDF Loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)"
      ],
      "metadata": {
        "id": "MifqadjtoW8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose\n",
        "    PyPDFLoader(\"/content/pca_d1.pdf\"),\n",
        "    PyPDFLoader(\"/content/ens_d2.pdf\"),\n",
        "    PyPDFLoader(\"/content/ens_d2.pdf\"),\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ],
      "metadata": {
        "id": "IrWOIYmAofck"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code cell, we are loading PDF documents. The code intends to load PDF documents using the PyPDFLoader class.\n",
        "\n",
        "Three instances of PyPDFLoader are created with paths to three different PDF files: pca_d1.pdf and ens_d2.pdf.\n",
        "\n",
        "**Note:** Please note that in the above code section, the **ens_d2.pdf** is included twice in the list of loaders to simulate duplicate documents. It was intentional to mimic data discrepancy that will give duplicate chunks in results.\n",
        "Later in this experiment, the Maximal Marginal Relevance (MMR) will handle it.\n",
        "* MMR will handle the duplicate chunks and give output only the diverse set.\n",
        "* The idea behind MMR is to find the most diverse set of documents, while also keeping the most relevant ones."
      ],
      "metadata": {
        "id": "6kRh9wNP_FhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "8N__DNS6r7kK",
        "outputId": "2986c5de-dd4f-4247-d87d-31b2fdecb956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "1  \n",
            " N  \n",
            "1 Principal  Component  Analysis  \n",
            "In real world data analysis tasks we analyze complex data i.e. multi dimensional data. We plot the  \n",
            "data and find various patterns in it or use it to train some machine learning models.  One way to  \n",
            "think  about  dimensions  is that  suppose  you have  an data  point  x , if we consider  this data  point  as \n",
            "a physical  object  then  dimensions  are merely  a basis  of view,  like where  is the data  located  when  \n",
            "it is observed  from  horizontal  axis or vertical  axis.  \n",
            "As the dimensions  of data  increases,  the difficulty  to visualize  it and perform  computations  on \n",
            "it also increases.  So, how  to reduce  the dimensions  of a data: - \n",
            "• Remove  the redundant  dimensions  \n",
            "• Only keep the most important dimensions  \n",
            "Let us first try to understand  some  terms: - \n",
            "Variance : It is a measure of the variability or it simply measures how spread the data set is.  \n",
            "Mathematically,  it is the average  squared  deviation  from  the mean  score.  We use the following  \n",
            "formula  to compute  variance  var(x).  \n",
            " \n",
            "var(x)  = Σ(xi−x¯)2 \n",
            "N \n",
            "Covariance :  It is a measure of the extent to which corresponding elements from two sets of  \n",
            "ordered data move in the same direction. Formula is shown below denoted by cov(x,y) as the  \n",
            "covariance  of x and y. \n",
            "var(x)  =  Σ(xi−x¯)(yi−y¯) \n",
            "• Here,  xi is the value  of x in ith dimension.  \n",
            "• x bar and y bar denote  the corresponding  mean  values.  \n",
            "• One  way  to observe  the covariance  is how  interrelated  two data  sets are. \n",
            "Positive covariance means X and Y are positively related i.e. as X increases Y also increases.  \n",
            "Negative covariance depicts the exact opposite relation.  However zero covariance means X and Y  \n",
            "are not related.  \n",
            "Now  lets think  about  the requirement  of data  analysis.  \n",
            "Since we try to find the patterns among the data sets so we want the data to be spread out  \n",
            "across each dimension. Also, we want the dimensions to be independent. Such that if data has high  \n",
            "covariance when represented in some n number of dimensions then we replace those dimensions  \n",
            "with linear combination of those n dimensions. Now that data will only be dependent on linear  \n",
            "combination  of those  related  n dimensions.  (related  = have  high  covariance)  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code cell, the docs[0] represents the first document object in the list of documents (docs).\n",
        "\n",
        "Each document object contains information about the PDF file it represents, such as metadata, text content, page structure, etc."
      ],
      "metadata": {
        "id": "4tLfwWe2BChO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "#from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50\n",
        ")"
      ],
      "metadata": {
        "id": "Y1qix4F0saSn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above approach, the Recursive Character Text Splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough.\n",
        "\n",
        "* The technique recursively splits a given text string into its individual characters.\n",
        "* It starts by breaking down the text into smaller substrings, each containing fewer characters.\n",
        "* This process continues recursively until each substring consists of only one character.\n",
        "* The recursion stops when the length of the substring becomes 1, indicating that it is a single character.\n",
        "At this point, the recursion stops, and the single character is returned.\n",
        "\n",
        "**chunk_size:** This parameter specifies the maximum number of characters in each chunk or substring after splitting. It basically determines the size of each chunk of text after splitting. We have kept chunk_size = 500. So, each chunk will contain at most 500 characters.\n",
        "\n",
        "**chunk_overlap:** This parameter specifies the number of characters that overlap between adjacent chunks. It helps ensure continuity and coherence between adjacent chunks by including some overlapping context. Here, we have kept chunk_overlap = 50. So, the last 50 characters of one chunk will overlap with the first 50 characters of the next chunk."
      ],
      "metadata": {
        "id": "x9L0RQfwCM-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splits = text_splitter.split_documents(docs)\n",
        "print(len(splits))\n",
        "splits"
      ],
      "metadata": {
        "id": "wHNEkTYTsbKg",
        "outputId": "f4c3a31c-cf58-4fb4-deb7-dd92979ced30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='1  \\n N  \\n1 Principal  Component  Analysis  \\nIn real world data analysis tasks we analyze complex data i.e. multi dimensional data. We plot the  \\ndata and find various patterns in it or use it to train some machine learning models.  One way to  \\nthink  about  dimensions  is that  suppose  you have  an data  point  x , if we consider  this data  point  as \\na physical  object  then  dimensions  are merely  a basis  of view,  like where  is the data  located  when', metadata={'source': '/content/pca_d1.pdf', 'page': 0}),\n",
              " Document(page_content='it is observed  from  horizontal  axis or vertical  axis.  \\nAs the dimensions  of data  increases,  the difficulty  to visualize  it and perform  computations  on \\nit also increases.  So, how  to reduce  the dimensions  of a data: - \\n• Remove  the redundant  dimensions  \\n• Only keep the most important dimensions  \\nLet us first try to understand  some  terms: - \\nVariance : It is a measure of the variability or it simply measures how spread the data set is.', metadata={'source': '/content/pca_d1.pdf', 'page': 0}),\n",
              " Document(page_content='Mathematically,  it is the average  squared  deviation  from  the mean  score.  We use the following  \\nformula  to compute  variance  var(x).  \\n \\nvar(x)  = Σ(xi−x¯)2 \\nN \\nCovariance :  It is a measure of the extent to which corresponding elements from two sets of  \\nordered data move in the same direction. Formula is shown below denoted by cov(x,y) as the  \\ncovariance  of x and y. \\nvar(x)  =  Σ(xi−x¯)(yi−y¯) \\n• Here,  xi is the value  of x in ith dimension.', metadata={'source': '/content/pca_d1.pdf', 'page': 0}),\n",
              " Document(page_content='• x bar and y bar denote  the corresponding  mean  values.  \\n• One  way  to observe  the covariance  is how  interrelated  two data  sets are. \\nPositive covariance means X and Y are positively related i.e. as X increases Y also increases.  \\nNegative covariance depicts the exact opposite relation.  However zero covariance means X and Y  \\nare not related.  \\nNow  lets think  about  the requirement  of data  analysis.', metadata={'source': '/content/pca_d1.pdf', 'page': 0}),\n",
              " Document(page_content='Since we try to find the patterns among the data sets so we want the data to be spread out  \\nacross each dimension. Also, we want the dimensions to be independent. Such that if data has high  \\ncovariance when represented in some n number of dimensions then we replace those dimensions  \\nwith linear combination of those n dimensions. Now that data will only be dependent on linear  \\ncombination  of those  related  n dimensions.  (related  = have  high  covariance)', metadata={'source': '/content/pca_d1.pdf', 'page': 0}),\n",
              " Document(page_content='2  \\n  \\nSo, what does  Principal  Component  Analysis  (PCA)  do?  \\nPCA finds a new set of dimensions (or a set of basis of views) such that all the dimensions are  \\northogonal (and hence linearly independent) and ranked according to the variance of data along  \\nthem. It means more important principle axis occurs first. (more important = more variance/more  \\nspread  out data)  \\n \\nHow  does  PCA  work?  \\n• Calculate  the covariance matrix  X of data  points.', metadata={'source': '/content/pca_d1.pdf', 'page': 1}),\n",
              " Document(page_content='• Calculate  eigenvectors  and corresponding  eigenvalues.  \\n• Sort  the eigenvectors  according  to their  eigenvalues  in decreasing  order.  \\n• Choose  first k eigenvectors  and that  will be the new  k dimensions.  \\n• Transform  the original  n dimensional  data  points  into k dimensions.  \\n \\nTo understand the detail working of PCA, we should have knowledge of eigen values and eigen  \\nvectors  \\n \\nEigenvectors:  The directions  in which  our data  are dispersed.', metadata={'source': '/content/pca_d1.pdf', 'page': 1}),\n",
              " Document(page_content='Eigenvalues:  The relative  importance  of these  different  directions.  \\n \\n[Covariance  matrix].[ Eigenvector]  = [eigenvalue].[Eigenvector]  \\nLets  look  into what  a covariance  matrix  is? \\nA covariance  matrix  of some  data  set in 4 dimensions  a,b,c,d.  \\n□ Va Ca,b Ca,c Ca,d Ca,e \\n \\n□ Ca,b Vb Cb,c Cb,d Cb,e \\n \\n \\n \\nVa : variance  along  dimension  a \\nCa,b  : Covariance  along  dimension  a and b', metadata={'source': '/content/pca_d1.pdf', 'page': 1}),\n",
              " Document(page_content='Ca,b  : Covariance  along  dimension  a and b \\nIf we have  a matrix  X of m*n  dimension  such  that  it holds  n data  points  of m dimensions,  then  \\ncovariance  matrix  can be calculated  as \\nC   =    1  (X − X¯ )(X − X¯ )T \\n x n−1 \\nIt is important  to note  that  the covariance  matrix  contains: - \\n• variance of  dimensions  as the main  diagonal  elements.  \\n• covariance  of dimensions  as the off diagonal  elements.', metadata={'source': '/content/pca_d1.pdf', 'page': 1}),\n",
              " Document(page_content='Also,  covariance  matrix  is symmetric  (observe  from  the image  above)  Ca,c Cb,c Vc Cc,d Cc e \\nCa,d Cb,d Cc,d Vd Cd e \\nCa,e Cb,e Cc,e Cd,e Ve', metadata={'source': '/content/pca_d1.pdf', 'page': 1}),\n",
              " Document(page_content='3  \\n  \\nAs, we discussed earlier we want the data to be spread out i.e. it should have high variance along  \\ndimensions. Also  we want to remove correlated dimensions i.e. covariance among the dimensions  \\nshould  be zero  (they  should  be linearly  independent).  \\nTherefore,  our covariance  matrix  should  have: - \\n• large  numbers  as the main  diagonal  elements.  \\n• zero  values  as the off diagonal  elements.', metadata={'source': '/content/pca_d1.pdf', 'page': 2}),\n",
              " Document(page_content='• zero  values  as the off diagonal  elements.  \\nWe call it a diagonal matrix. So, we have to transform the original data points such that their  \\ncovariance  is a diagonal  matrix.  \\nAlways  normalize  your  data  before  doing  PCA if we use data  (features  here)  of different  scales,  we \\nget misleading components. We can also simply use correlation matrix instead of using covariance  \\nmatrix  if features  are of different  scales.  \\nThis defines  the goal  of PCA: -', metadata={'source': '/content/pca_d1.pdf', 'page': 2}),\n",
              " Document(page_content='This defines  the goal  of PCA: - \\n1. Find  linearly  independent  dimensions  which  can losslessly  represent  the data  points.  \\n2. Those  newly  found  dimensions  should  allow  us to predict/reconstruct  the original  dimensions.', metadata={'source': '/content/pca_d1.pdf', 'page': 2}),\n",
              " Document(page_content='1   \\nEnsemble  Methods  \\nLet us consider  a real  world  situation  which  uses  Ensemble  Methods,  which  is, when  a user  wants  \\nto buy a new product. Many users who have already purchased that product will have given either  \\npositive  or negative  ratings.  If in the group,  many  users  have  given  positive  ratings,  then  the \\ncombined  rating  will be positive.  Instead  of a single  rating,  the ratings  of the group  of users  is', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='considered.  The product  is bought  by the user  when  the combined  ratings  of the group  is positive.  \\nThe user  gets  a fairer  idea  about  the product  when  all the ratings  are combined.  \\nHere, the combination of ratings is done so that the decision making process of the user is made  \\neasy.  \\nEnsemble Methods refer to combining many different machine learning models in order to get a  \\nmore  powerful  prediction.', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='more  powerful  prediction.  \\nThus,  ensemble  methods  increase  the accuracy  of the predictions.  \\n \\nWhy  use Ensemble  Methods?  \\nEnsemble  Methods  are used  in order  to: \\n• decrease  variance  (bagging)  \\n• decrease  bias (boosting)  \\n• improve  predictions  (stacking)  \\n \\nBagging  \\nBagging  actually  refers  to Bootstrap  Aggregators.  \\nBagging tests multiple models on the data by sampling and replacing data i.e it utilizes bootstrap -', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='ping.  In turn,  this reduces  the noise  and variance  by utilizing  multiple  samples.  Each  hypothesis  \\nhas the same  weight  as all the others.  Now,  aggregating  of the outputs  of various  models  is done.  \\n \\nBoosting  \\nBoosting is an iterative technique which adjusts the weight of an observation based on the last  \\nclassification. If an observation was classified incorrectly, it tries to increase the weight of this', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='observation and vice versa. Boosting in general decreases the bias error and builds strong predictive  \\nmodels.  \\n \\nVariance  \\nVariance quantifies how the predictions made on same observation are different from each other. A  \\nhigh variance model will over -fit on your training population and perform badly on any observation  \\nbeyond  training.  Thus,  we aim at low variance.', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='2   \\nBias  \\nBias error is useful to quantify how much on on average are the predicted values different from the  \\nactual value. A high  bias  error means we have a under -performing model.  Thus,  we aim at low  \\nbias.  \\nA commonly  used  class  of ensemble  methods  are forests  of randomized  trees.  \\nIn random  forests,  each  tree  in the ensemble  is built  from  a sample  drawn  with  replacement  (i.e.', metadata={'source': '/content/ens_d2.pdf', 'page': 1}),\n",
              " Document(page_content='a bootstrap sample) from the training set. In addition, instead of using all the features, a random  \\nsubset  of features  is selected,  further  randomizing  the tree.  \\nAs a result, the bias of the forest increases slightly, but due to the averaging of less correlated  \\ntrees,  its variance  decreases,  resulting  in an overall  better  model.', metadata={'source': '/content/ens_d2.pdf', 'page': 1}),\n",
              " Document(page_content='1   \\nEnsemble  Methods  \\nLet us consider  a real  world  situation  which  uses  Ensemble  Methods,  which  is, when  a user  wants  \\nto buy a new product. Many users who have already purchased that product will have given either  \\npositive  or negative  ratings.  If in the group,  many  users  have  given  positive  ratings,  then  the \\ncombined  rating  will be positive.  Instead  of a single  rating,  the ratings  of the group  of users  is', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='considered.  The product  is bought  by the user  when  the combined  ratings  of the group  is positive.  \\nThe user  gets  a fairer  idea  about  the product  when  all the ratings  are combined.  \\nHere, the combination of ratings is done so that the decision making process of the user is made  \\neasy.  \\nEnsemble Methods refer to combining many different machine learning models in order to get a  \\nmore  powerful  prediction.', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='more  powerful  prediction.  \\nThus,  ensemble  methods  increase  the accuracy  of the predictions.  \\n \\nWhy  use Ensemble  Methods?  \\nEnsemble  Methods  are used  in order  to: \\n• decrease  variance  (bagging)  \\n• decrease  bias (boosting)  \\n• improve  predictions  (stacking)  \\n \\nBagging  \\nBagging  actually  refers  to Bootstrap  Aggregators.  \\nBagging tests multiple models on the data by sampling and replacing data i.e it utilizes bootstrap -', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='ping.  In turn,  this reduces  the noise  and variance  by utilizing  multiple  samples.  Each  hypothesis  \\nhas the same  weight  as all the others.  Now,  aggregating  of the outputs  of various  models  is done.  \\n \\nBoosting  \\nBoosting is an iterative technique which adjusts the weight of an observation based on the last  \\nclassification. If an observation was classified incorrectly, it tries to increase the weight of this', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='observation and vice versa. Boosting in general decreases the bias error and builds strong predictive  \\nmodels.  \\n \\nVariance  \\nVariance quantifies how the predictions made on same observation are different from each other. A  \\nhigh variance model will over -fit on your training population and perform badly on any observation  \\nbeyond  training.  Thus,  we aim at low variance.', metadata={'source': '/content/ens_d2.pdf', 'page': 0}),\n",
              " Document(page_content='2   \\nBias  \\nBias error is useful to quantify how much on on average are the predicted values different from the  \\nactual value. A high  bias  error means we have a under -performing model.  Thus,  we aim at low  \\nbias.  \\nA commonly  used  class  of ensemble  methods  are forests  of randomized  trees.  \\nIn random  forests,  each  tree  in the ensemble  is built  from  a sample  drawn  with  replacement  (i.e.', metadata={'source': '/content/ens_d2.pdf', 'page': 1}),\n",
              " Document(page_content='a bootstrap sample) from the training set. In addition, instead of using all the features, a random  \\nsubset  of features  is selected,  further  randomizing  the tree.  \\nAs a result, the bias of the forest increases slightly, but due to the averaging of less correlated  \\ntrees,  its variance  decreases,  resulting  in an overall  better  model.', metadata={'source': '/content/ens_d2.pdf', 'page': 1})]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Embeddings**\n",
        "\n",
        "Let's take our splits and embed them."
      ],
      "metadata": {
        "id": "HRYXCWXxsmH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **HuggingFaceHubEmbeddings** class is responsible for generating embeddings (vector representations) of text using pre-trained models available on the Hugging Face Model Hub.\n",
        "* HuggingFaceHubEmbeddings utilizes pre-trained language models (BERT, RoBERTa, GPT, etc.) from the Hugging Face Model Hub to generate embeddings for input text.\n",
        "* These embeddings capture semantic information about the text, representing it in a continuous vector space.\n",
        "* By making use of the pre-trained models from the Hugging Face Model Hub, **HuggingFaceHubEmbeddings** allows for the generation of high-quality embeddings without the need for extensive training data or computational resources.\n",
        "* So, it provides a convenient and efficient way to incorporate state-of-the-art semantic representations into NLP pipelines and applications.\n",
        "* After instantiation, the **HuggingFaceHubEmbeddings** instance can be used to generate embeddings for input text by calling its methods like **embed_query()**.\n",
        "* These embeddings can then be used as input features for the downstream natural language processing task **(similarity search)**."
      ],
      "metadata": {
        "id": "UWzeYmzkGhqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = HuggingFaceHubEmbeddings()"
      ],
      "metadata": {
        "id": "cw8TrmK89kJl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "id": "paxP3GEUuSaS",
        "outputId": "ba508e88-ae5f-488a-f807-f4f26f9c182c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HuggingFaceHubEmbeddings(client=<InferenceClient(model='sentence-transformers/all-mpnet-base-v2', timeout=None)>, async_client=<InferenceClient(model='sentence-transformers/all-mpnet-base-v2', timeout=None)>, model='sentence-transformers/all-mpnet-base-v2', repo_id='sentence-transformers/all-mpnet-base-v2', task='feature-extraction', model_kwargs=None, huggingfacehub_api_token=None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Understanding similarity search with a toy example**\n",
        "\n",
        "1. **Vector Space Representation:**\n",
        "* Each sentence is converted into a high-dimensional vector representation in a continuous vector space.\n",
        "* This transformation is performed using embedding techniques, where words or tokens in the sentences are mapped to vectors in the vector space.\n",
        "* The resulting vectors capture semantic information about the sentences, with similar sentences being mapped closer together in the vector space.\n",
        "\n",
        "2. **Dot Product:**\n",
        "* The dot product is a mathematical operation that measures the similarity or alignment between two vectors.\n",
        "* It calculates the cosine of the angle between the two vectors, with higher values indicating greater similarity.\n",
        "* For two vectors **$a$ and $b$**, the dot product **$a.b$** is calculated as the sum of the element-wise products of the two vectors.\n",
        "\n",
        "3. **Similarity Measurement:**\n",
        "\n",
        "* In the provided code, the dot product is calculated between the embeddings of different sentences to measure their similarity.\n",
        "* For example, **np.dot(embedding1, embedding2)** computes the similarity between **sentence1 and sentence2**.\n",
        "* Similarly, **np.dot(embedding1, embedding3) and np.dot(embedding2, embedding3)** compute the similarities between **sentence1 and sentence3**, and between **sentence2 and sentence3**, respectively.\n",
        "\n",
        "4. **Interpretation:**\n",
        "* A higher dot product value indicates greater similarity between the corresponding sentences in the vector space.\n",
        "* By comparing the dot product values between different pairs of sentences, we can assess their semantic similarity or relatedness.\n",
        "* In the toy example provided below, we evaluate the similarities between **sentence1 & sentence2**, **sentence1 & sentence3**, and **sentence2 & sentence3**.\n",
        "\n"
      ],
      "metadata": {
        "id": "OtqIaNDTsq3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"i like dogs\"\n",
        "sentence2 = \"i like cats\"\n",
        "sentence3 = \"the weather is ugly, too hot outside\""
      ],
      "metadata": {
        "id": "prWJAL50szYO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding1 = embedding.embed_query(sentence1)\n",
        "embedding2 = embedding.embed_query(sentence2)\n",
        "embedding3 = embedding.embed_query(sentence3)"
      ],
      "metadata": {
        "id": "iAeeFUsis1wO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding1), len(embedding2), len(embedding3)"
      ],
      "metadata": {
        "id": "nGc4yWSas4RX",
        "outputId": "cab15049-059f-4d6e-951d-f58148e6ae53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 768, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot(embedding1, embedding2), np.dot(embedding1, embedding3),np.dot(embedding2, embedding3)"
      ],
      "metadata": {
        "id": "lDbU70Zss6j4",
        "outputId": "3f153dba-a2b0-449d-9fa5-b6c5766a2ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7948764601906951, 0.1009330745675062, 0.10528326984050976)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vectorstores**\n",
        "\n",
        "In the following code cell, the Chroma.from_documents(...) method is executed, which processes the provided documents, generates embeddings for each document using the specified embedding model, and indexes them in the Chroma object."
      ],
      "metadata": {
        "id": "osU6iYMLswJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'docs/chroma/'\n",
        "!rm -rf ./docs/chroma  # remove old database files if any"
      ],
      "metadata": {
        "id": "oI9whQjptqav"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits, # splits we created earlier\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory # save the directory\n",
        ")"
      ],
      "metadata": {
        "id": "BPeW91Qdtxmw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code cell, in order to enable fast similarity search operations, we use Chroma Object (vectordb) for storing the document embeddings in an efficient data structure, such as a spatial index or a hash table.\n",
        "* The resulting Chroma object, named **vectordb**, contains the indexed documents and their embeddings.\n",
        "* It provides methods for querying the indexed documents based on similarity to a given query document or vector\n",
        "* Additionally, it may support operations such as nearest neighbor search, clustering, and retrieval of similar documents."
      ],
      "metadata": {
        "id": "gRunbTu5jrRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist() # Let's **save vectordb** so we can use it later!"
      ],
      "metadata": {
        "id": "HncL1qsEt3RQ",
        "outputId": "ac49b6c5-55cd-437b-e027-fc2e73774a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectordb._collection.count()) # same as number of splites"
      ],
      "metadata": {
        "id": "BxEeyHgjt0Po",
        "outputId": "ca387a24-9e4d-4c88-eb10-154c9f94be77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Similarity Search**\n",
        "\n",
        "In the following approach, the **vectordb.similarity_search(...)** method is called to perform the similarity search.\n",
        "\n",
        "The method takes the query question (question) as input and returns a list of documents similar to the query question based on their embeddings stored in the vectordb object.\n",
        "\n",
        "The parameter k=3 specifies that we want to retrieve the top 3 most similar documents as the search result."
      ],
      "metadata": {
        "id": "0-2WgevOt_TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"how does pca reduce the dimension?\""
      ],
      "metadata": {
        "id": "_OUYY3Mot2nL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = vectordb.similarity_search(question,k=3) # k --> No. of doc as return\n",
        "print(len(docs))\n",
        "print(docs[0].page_content)\n",
        "print(docs[1].page_content)\n",
        "print(docs[2].page_content)"
      ],
      "metadata": {
        "id": "DGHDzVj4uyx3",
        "outputId": "e9a92a8c-d9fb-473c-b4ba-f7b9478d8664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "This defines  the goal  of PCA: - \n",
            "1. Find  linearly  independent  dimensions  which  can losslessly  represent  the data  points.  \n",
            "2. Those  newly  found  dimensions  should  allow  us to predict/reconstruct  the original  dimensions.\n",
            "1  \n",
            " N  \n",
            "1 Principal  Component  Analysis  \n",
            "In real world data analysis tasks we analyze complex data i.e. multi dimensional data. We plot the  \n",
            "data and find various patterns in it or use it to train some machine learning models.  One way to  \n",
            "think  about  dimensions  is that  suppose  you have  an data  point  x , if we consider  this data  point  as \n",
            "a physical  object  then  dimensions  are merely  a basis  of view,  like where  is the data  located  when\n",
            "2  \n",
            "  \n",
            "So, what does  Principal  Component  Analysis  (PCA)  do?  \n",
            "PCA finds a new set of dimensions (or a set of basis of views) such that all the dimensions are  \n",
            "orthogonal (and hence linearly independent) and ranked according to the variance of data along  \n",
            "them. It means more important principle axis occurs first. (more important = more variance/more  \n",
            "spread  out data)  \n",
            " \n",
            "How  does  PCA  work?  \n",
            "• Calculate  the covariance matrix  X of data  points.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code cell, the variable 'question' contains the query question for which we want to find similar documents. In this scenario, the query question is **\"how does pca reduce the dimension?\"**\n",
        "\n",
        "* As per the above result, the returned list of documents (docs) contains the search results, with each document representing a similar document to the query question.\n",
        "* The length of the docs list is printed using print(len(docs)) to display the number of similar documents retrieved.\n",
        "* Then, the content of the top 3 similar documents is printed using print(docs[0].page_content), print(docs[1].page_content), and print(docs[2].page_content), respectively."
      ],
      "metadata": {
        "id": "YLMjhit7lgzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Edge case where failure may happen**\n",
        "\n",
        "1. Lack of Diversity : Semantic search fetches all similar documents, but does not enforce diversity.\n",
        "\n",
        "    - Notice that we're getting duplicate chunks (because of the duplicate `ens_d2.pdf` in the index). `docs[0]` and `docs[1]` are non-identical.\n",
        "\n",
        "  **Addressing Diversity - MMR-Maximum Marginal Relevance**\n",
        "\n",
        "2. Lack of specificity:  The question may be from a particular doc but answer may contain information from other doc.\n",
        "\n",
        "  **Addressing Specificity: Working with metadata - Manually**\n",
        "\n",
        "  **Working with metadata using self-query retriever -Automatically**"
      ],
      "metadata": {
        "id": "qBh5fXjrwHw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  **Example 1. Addressing Diversity - MMR-Maximum Marginal Relevance**"
      ],
      "metadata": {
        "id": "UJNlYo983oZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question= 'how ensemble method works?'\n",
        "docs = vectordb.similarity_search(question,k=2) # Without MMR"
      ],
      "metadata": {
        "id": "TBdrnHC3uy0n"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "L9huk6xy3xWW",
        "outputId": "3c8816b5-855e-4b93-e3f1-9b0bf564ccc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='1   \\nEnsemble  Methods  \\nLet us consider  a real  world  situation  which  uses  Ensemble  Methods,  which  is, when  a user  wants  \\nto buy a new product. Many users who have already purchased that product will have given either  \\npositive  or negative  ratings.  If in the group,  many  users  have  given  positive  ratings,  then  the \\ncombined  rating  will be positive.  Instead  of a single  rating,  the ratings  of the group  of users  is', metadata={'page': 0, 'source': '/content/ens_d2.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1]"
      ],
      "metadata": {
        "id": "vHBRG8p-4RF6",
        "outputId": "03178587-4f6b-45bc-cc9a-9ee3d0ef6434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='1   \\nEnsemble  Methods  \\nLet us consider  a real  world  situation  which  uses  Ensemble  Methods,  which  is, when  a user  wants  \\nto buy a new product. Many users who have already purchased that product will have given either  \\npositive  or negative  ratings.  If in the group,  many  users  have  given  positive  ratings,  then  the \\ncombined  rating  will be positive.  Instead  of a single  rating,  the ratings  of the group  of users  is', metadata={'page': 0, 'source': '/content/ens_d2.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell, the **max_marginal_relevance_search** function with **Maximal Marginal Relevance (MMR)** is a method used to perform a similarity search with the addition of a relevance-based diversification component."
      ],
      "metadata": {
        "id": "J08akXtlpxpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_with_mmr=vectordb.max_marginal_relevance_search(question, k=3, fetch_k=6) # With MMR"
      ],
      "metadata": {
        "id": "Qg70_vhh5e7x"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_with_mmr[0]"
      ],
      "metadata": {
        "id": "3r_KetcH5wDj",
        "outputId": "0cd70b58-d95e-41e9-8d9c-cbb8e72ee71b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='1   \\nEnsemble  Methods  \\nLet us consider  a real  world  situation  which  uses  Ensemble  Methods,  which  is, when  a user  wants  \\nto buy a new product. Many users who have already purchased that product will have given either  \\npositive  or negative  ratings.  If in the group,  many  users  have  given  positive  ratings,  then  the \\ncombined  rating  will be positive.  Instead  of a single  rating,  the ratings  of the group  of users  is', metadata={'page': 0, 'source': '/content/ens_d2.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In the above result, **docs_with_mmr[0]** represents the document with the highest relevance score according to the MMR algorithm.\n",
        "2. This document is expected to have a high similarity to the query question while also providing diverse information compared to the other search results.\n",
        "3. The MMR algorithm aims to balance relevance and diversity, so **docs_with_mmr[0]** should be both relevant and distinct from the other documents in the search results."
      ],
      "metadata": {
        "id": "3QbTINPuqRhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_with_mmr[1]"
      ],
      "metadata": {
        "id": "vppdq9Bn5y0z",
        "outputId": "bc118bdd-7411-4236-903b-d683e30d280f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='considered.  The product  is bought  by the user  when  the combined  ratings  of the group  is positive.  \\nThe user  gets  a fairer  idea  about  the product  when  all the ratings  are combined.  \\nHere, the combination of ratings is done so that the decision making process of the user is made  \\neasy.  \\nEnsemble Methods refer to combining many different machine learning models in order to get a  \\nmore  powerful  prediction.', metadata={'page': 0, 'source': '/content/ens_d2.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In the above result, **docs_with_mmr[1]** represents the second most relevant document according to the MMR algorithm.\n",
        "2. While still relevant to the query question, **docs_with_mmr[1]** may contain information that is slightly less similar to the query compared to **docs_with_mmr[0]**."
      ],
      "metadata": {
        "id": "AW0kPoloqpDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_with_mmr[2]"
      ],
      "metadata": {
        "id": "uLqM_I87-thH",
        "outputId": "d5e19972-2848-47bb-82cc-f870b5c6f4ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='more  powerful  prediction.  \\nThus,  ensemble  methods  increase  the accuracy  of the predictions.  \\n \\nWhy  use Ensemble  Methods?  \\nEnsemble  Methods  are used  in order  to: \\n• decrease  variance  (bagging)  \\n• decrease  bias (boosting)  \\n• improve  predictions  (stacking)  \\n \\nBagging  \\nBagging  actually  refers  to Bootstrap  Aggregators.  \\nBagging tests multiple models on the data by sampling and replacing data i.e it utilizes bootstrap -', metadata={'page': 0, 'source': '/content/ens_d2.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Similarly, the above output of the **docs_with_mmr[2]** represents the third most relevant document based on the MMR algorithm.\n",
        "2. It is expected to be relevant to the query question but may contain information that is more diverse compared to **docs_with_mmr[0]** and **docs_with_mmr[1]**."
      ],
      "metadata": {
        "id": "6TW6fiafq-Dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Example 2. Addressing Specificity: Working with metadata - Manually**\n",
        "\n",
        "**Specificity:**\n",
        "* In information retrieval tasks such as similarity search, addressing specificity refers to obtaining search results that are relevant and specific to the user's query.\n",
        "* When dealing with large document collections, it's common for similarity search algorithms to retrieve documents that are relevant but not necessarily specific to the user's query.\n",
        "* By working with metadata associated with documents, we can provide additional context and information about the search results, helping users assess the relevance and specificity of the retrieved documents.\n",
        "* Metadata contains information about the documents, such as titles, authors, publication dates, or any other relevant information."
      ],
      "metadata": {
        "id": "vZYR1s6x_bpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- In the following code cell, the code starts with a query question defined as question = **\"what is the role of variance in pca?\"**.\n",
        "\n",
        "-- The **vectordb.similarity_search(...)** method is called to perform a similarity search based on the query question.\n",
        "\n",
        "-- The parameter k=5 specifies that the top 5 most similar documents should be retrieved as search results."
      ],
      "metadata": {
        "id": "vp_6LavntclV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Without metadata information\n",
        "question = \"what is the role of variance in pca?\"\n",
        "docs = vectordb.similarity_search(question,k=5)\n",
        "for doc in docs:\n",
        "    print(doc.metadata) # metadata contains information about from which doc the answer has been fetched"
      ],
      "metadata": {
        "id": "9GzDPqSVAX6Y",
        "outputId": "1fb682c3-f854-4e5f-86fe-489f80eb752f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page': 1, 'source': '/content/pca_d1.pdf'}\n",
            "{'page': 2, 'source': '/content/pca_d1.pdf'}\n",
            "{'page': 1, 'source': '/content/pca_d1.pdf'}\n",
            "{'page': 2, 'source': '/content/pca_d1.pdf'}\n",
            "{'page': 0, 'source': '/content/pca_d1.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With metadata information\n",
        "question = \"what is the role of variance in pca?\"\n",
        "docs = vectordb.similarity_search(\n",
        "    question,\n",
        "    k=5,\n",
        "    filter={\"source\":'/content/pca_d1.pdf'} # manually passing metadata, using metadata filter.\n",
        ")\n",
        "\n",
        "for doc in docs:\n",
        "    print(doc.metadata)"
      ],
      "metadata": {
        "id": "P-9NluQR_VUi",
        "outputId": "074eeee2-7cfb-4d7d-a486-88e82a51f08b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page': 1, 'source': '/content/pca_d1.pdf'}\n",
            "{'page': 2, 'source': '/content/pca_d1.pdf'}\n",
            "{'page': 1, 'source': '/content/pca_d1.pdf'}\n",
            "{'page': 2, 'source': '/content/pca_d1.pdf'}\n",
            "{'page': 0, 'source': '/content/pca_d1.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Addressing Specificity -Automatically: Working with metadata using self-query retriever**](https://python.langchain.com/docs/modules/data_connection/retrievers/self_query)\n",
        "\n"
      ],
      "metadata": {
        "id": "tiFz42WiCJUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Additional tricks: Compression**\n",
        "\n",
        "Another approach for improving the quality of retrieved docs is compression. Information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
        "\n",
        "[Contextual compression](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression) is meant to fix this.\n",
        "\n",
        "To use the Contextual Compression Retriever, you'll need:\n",
        "\n",
        "* a base retriever\n",
        "* a Document Compressor\n",
        "\n",
        "The Contextual Compression Retriever passes queries to the base retriever, takes the initial documents and passes them through the Document Compressor. The Document Compressor takes a list of documents and shortens it by reducing the contents of documents or dropping documents altogether."
      ],
      "metadata": {
        "id": "qQG1e-boGTTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Retrieval + Question Answering :  Connecting with LLMs**\n",
        "\n",
        "Connecting with LLMs typically involves initializing an instance of the chosen model and setting up parameters for its usage.\n",
        "\n",
        "* In the following code, it merely assigns the name of the LLM to a variable and prints it.\n",
        "* In this case, it will print \"gpt-3.5-turbo\", indicating the name of the chosen LLM."
      ],
      "metadata": {
        "id": "2aIGynCLGw0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_name = \"gpt-3.5-turbo\"\n",
        "print(llm_name)"
      ],
      "metadata": {
        "id": "ehEr-pUMGMrK",
        "outputId": "f55ea72e-765d-424f-be0d-ff15b21a57dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-3.5-turbo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell, **max_marginal_relevance_search** is a function or method used to perform a similarity search with the addition of a relevance-based diversification component, typically using the Maximal Marginal Relevance (MMR) algorithm.\n",
        "\n",
        "This function retrieves documents from the vectordb that are both relevant to the query and diverse from each other, according to specified criteria.\n",
        "\n",
        "**question** is a variable containing the query question for which we want to find similar documents.\n",
        "In this case, the query question is \"**What is principal component analysis?**\"\n",
        "\n",
        "The parameter **k=2** specifies that we want to retrieve the top 2 most relevant and diverse documents as the search result.\n",
        "\n",
        "The parameter **fetch_k=3** specifies that, for each relevant document retrieved, the function should also fetch additional related documents to ensure diversity.\n",
        "In this case, for each of the top 2 relevant documents retrieved, the function will also fetch 3 additional related documents to consider for diversification."
      ],
      "metadata": {
        "id": "piwnd4O7vTHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is principal component analysis?\"\n",
        "docs = vectordb.max_marginal_relevance_search(question, k=2, fetch_k=3)\n",
        "len(docs)"
      ],
      "metadata": {
        "id": "Oc8EF156G3uv",
        "outputId": "fa83fff9-0be1-4d23-cba7-07feb0ff7f08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "OpV03kILH6vl",
        "outputId": "6d5527f7-48aa-4740-e665-a29ab58f126c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='2  \\n  \\nSo, what does  Principal  Component  Analysis  (PCA)  do?  \\nPCA finds a new set of dimensions (or a set of basis of views) such that all the dimensions are  \\northogonal (and hence linearly independent) and ranked according to the variance of data along  \\nthem. It means more important principle axis occurs first. (more important = more variance/more  \\nspread  out data)  \\n \\nHow  does  PCA  work?  \\n• Calculate  the covariance matrix  X of data  points.', metadata={'page': 1, 'source': '/content/pca_d1.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1]"
      ],
      "metadata": {
        "id": "Mr4vt1ArIEWX",
        "outputId": "cc5c6cb8-0fae-495c-f5bf-82c0712d48f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='1  \\n N  \\n1 Principal  Component  Analysis  \\nIn real world data analysis tasks we analyze complex data i.e. multi dimensional data. We plot the  \\ndata and find various patterns in it or use it to train some machine learning models.  One way to  \\nthink  about  dimensions  is that  suppose  you have  an data  point  x , if we consider  this data  point  as \\na physical  object  then  dimensions  are merely  a basis  of view,  like where  is the data  located  when', metadata={'page': 0, 'source': '/content/pca_d1.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**[RetrievalQA chain](https://docs.smith.langchain.com/cookbook/hub-examples/retrieval-qa-chain)**\n",
        "\n",
        "Retrieval methods retrieve a set of candidate documents\n",
        "$D$ = ${d_{1}, d_{2}, ...., d_{n}}$ from a larger corpus based on their relevance to the query $q$.\n",
        "This can be represented as:\n",
        "$D=Retrieve(q)$\n",
        "\n",
        "QA models are then applied to the retrieved documents to generate candidate answers $A$ = ${a_{1}, a_{2}, ...., a_{n}}$ to the user query $q$. This can be represented as:\n",
        "$A=QA(D,q)$\n",
        "\n",
        "The final answer $a_{final}$ is selected from the candidate answers based on various criteria, such as relevance, confidence scores, or other heuristics. This can be represented as:\n",
        "$a_{final}$ = $Select(A)$\n",
        "\n",
        "####**[Vector store-backed retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore)**\n",
        "\n",
        "A vector store retriever is a retriever that uses a vector store to retrieve documents. It is a lightweight wrapper around the vector store class to make it conform to the retriever interface. It uses the search methods implemented by a vector store, like similarity search and MMR, to query the texts in the vector store.\n",
        "\n",
        "Once you construct a vector store, it's very easy to construct a retriever. Let's walk through the following example."
      ],
      "metadata": {
        "id": "eC-7gtzfHQYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell, we initialize a HuggingFaceEndpoint object named **chat_llm**, which connects to a Hugging Face model endpoint for text generation.\n",
        "\n",
        "* **repo_id:** It specifies the repository ID of the Hugging Face model to connect to.\n",
        "* **task:** It defines the task for which the model will be used, in this case, \"text-generation\".\n",
        "* **max_new_tokens:** This sets the maximum number of new tokens that can be generated in each response.\n",
        "* **top_k:** This parameter controls the number of top-k tokens considered during text generation.\n",
        "* **temperature:** This parameter adjusts the diversity of the generated text by scaling the logits before applying the softmax function.\n",
        "* **repetition_penalty:** It penalizes the likelihood of generating repeated tokens in the generated text."
      ],
      "metadata": {
        "id": "rvffVPNS0SLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens = 512,\n",
        "    top_k = 30,\n",
        "    temperature = 0.1,\n",
        "    repetition_penalty = 1.03,\n",
        ")"
      ],
      "metadata": {
        "id": "lfUZEUCIANQN",
        "outputId": "ad97362c-e1b0-41ff-98ed-2c6490c7efcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell, we have instantiated **ChatHuggingFace**\n",
        "1. It is a wrapper for using Hugging Face LLM’s as ChatModels.\n",
        "2. It works with HuggingFaceTextGenInference, HuggingFaceEndpoint, and HuggingFaceHub LLMs.\n",
        "3. Upon instantiating this class, the model_id is resolved from the url provided to the LLM, and the appropriate tokenizer is loaded from the HuggingFace Hub.\n",
        "4. Once instantiated, ChatHuggingFace establishes a connection to the specified Hugging Face model endpoint (chat_llm) for chat-based interactions.\n",
        "5. **Conversation Handling:** It provides methods to handle conversation flows such as sending messages, receiving responses, and maintaining context during the conversation.\n",
        "6. This is adapted from: [llama2_chat](https://python.langchain.com/docs/integrations/chat/llama2_chat)\n",
        "7. It creates a new model by parsing and validating input data from keyword arguments.\n",
        "8. **Text Generation:** Utilizing the Hugging Face model endpoint, ChatHuggingFace, it can generate text responses to incoming messages or prompts, leveraging the capabilities of the underlying model for text generation tasks.\n",
        "9. It raises ValidationError if the input data cannot be parsed to form a valid model."
      ],
      "metadata": {
        "id": "yDkVyIoA2zAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatHuggingFace(llm=chat_llm)"
      ],
      "metadata": {
        "id": "GMvW6RuM_6x8",
        "outputId": "b22562fa-e4f9-4c8d-fe9b-ccfd0ab3ccf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "efb6b5aec3cc4a7aa0609e42ccb3aa64",
            "46ceb8e3a7af464a82bcbcf78459cc8a",
            "550b9df56cee4f988e3fe3ab747896e7",
            "656fd737fc7c4e9797932943537f7c45",
            "7283ad4e7e9a4569ae85810bcfb0650c",
            "158291693e4340f7a57f7e9de651b6ac",
            "0792045f9de248ba84dc1e25d6387efd",
            "4e1b34dbabfe4d33900f07445faae468",
            "7965d94feca74cc68f655d9b6fe64727",
            "d7c0b2dd81c445e994b1ecd12dbcbdb4",
            "7913fd12392749aba6a01b9e05a6445f",
            "6988e3c3a54b4734a9d25febce22a5a7",
            "57475090993c4e888b386aa7217a9b56",
            "6e223cfefc664945bd442ee574ec2ffc",
            "ea0b78f05c9048bb88574954bdce0842",
            "683cd2017cd842a8a2b6f7873037f092",
            "50432d5640014a04bafeff0f66ba890b",
            "58e7365ab1cf4bc3ba77649e27f74675",
            "d55b8d5b2e3d4263a9452ea79d3cf545",
            "0d62ab39fb9f449784d662cbb138ca55",
            "78b8e8779cf34a8eb2194d708ed5f462",
            "9e189e1f3ae94e1984fe7487753218b8",
            "4099ce9977024fccbd54c9438cac0fbc",
            "5c4ac7c44d28411cad0328ea2d38b6df",
            "8a3b37ea16254459b2977836302b5b82",
            "b2e82ad6dbc94460b20434051a4c7d01",
            "381c71520a5c4b09bcdec5fa2799f61f",
            "6bf34591f43e4a18bb6070584e574fba",
            "e228046479fb4aa89e6ca488a48d0d48",
            "b9d59258de684859bfcd43792725b5d6",
            "d1bd782005cf423d83af90929f514ddd",
            "c2c6155cf8654752aae3d771de021a54",
            "d5acd81c82e9435eb5a54cefe49ccc17",
            "e33df6577ea34e0f87479e1a4c157372",
            "1954155914b8436ab9c6fb7cb55aea6c",
            "cf99fc19b3a34524b9b232f53914eb8b",
            "53bb1c76546f44ed9a1fa684540ebcfa",
            "682fc224254b4705a7a3a968996d86ab",
            "b91585cb397d476eb05f3a510751d1ab",
            "39bfb88b23f24f128c5f739072d5eca7",
            "56c6aedda9084ef199bec7a0a3c5d9a9",
            "12248540fabd4bfd89295f7f5371ce6a",
            "b8cb5374d98b449db1728e339ad0959d",
            "d7d3afab4f6f475e822217d5aca18865",
            "437f3f7d6cc84e8facee3c33a8f2a600",
            "cf80c5ada22e4fd0bba8efe5c95c1470",
            "6ab0967225ff40929ea9f5440fffe444",
            "56826c3e2fa647968207982c9d6b0d49",
            "80a0277d919e4d20ad1907ce561fc537",
            "ecc4f3f671fa4ced830cd6ce44da599e",
            "5412a815f46b4cba9bc9dcbeacd25521",
            "1e4e45ef2ac549e5b21817e122d22a7a",
            "11e86fcb4b55431f9c2dc4d1f5809738",
            "e04b9395d09d4bb19422031004555f4e",
            "ac8a9a0c402f4de2945d9789295350fe"
          ]
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatHuggingFace` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface.chat_models import huggingface import ChatHuggingFace`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efb6b5aec3cc4a7aa0609e42ccb3aa64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6988e3c3a54b4734a9d25febce22a5a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4099ce9977024fccbd54c9438cac0fbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e33df6577ea34e0f87479e1a4c157372"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "437f3f7d6cc84e8facee3c33a8f2a600"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is principal component analysis?\"\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectordb.as_retriever(), return_source_documents=True)\n",
        "\n",
        "result = qa_chain.invoke({\"query\": question})"
      ],
      "metadata": {
        "id": "oFygf_Y7HWQ5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "A-yxS2awHWT7",
        "outputId": "0ca02c2c-dc23-4702-e29d-1628833da2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Principal Component Analysis (PCA) is a statistical technique used to analyze complex data with multiple dimensions. It finds a new set of dimensions (also called principal components) that are orthogonal (linearly independent) and ranked based on the variance of the data along them. The goal of PCA is to find linearly independent dimensions that can losslessly represent the data points and allow us to predict or reconstruct the original dimensions. By transforming the original data points such that their covariance becomes a diagonal matrix, we can achieve this goal. Normalizing the data before doing PCA is recommended if the features have different scales to avoid misleading components. In summary, PCA helps to simplify complex data by reducing the number of dimensions and identifying the most important features.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "id": "wBOgOkjPOvmO",
        "outputId": "9186b80b-7be4-42ed-fa99-91d315768a5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='2  \\n  \\nSo, what does  Principal  Component  Analysis  (PCA)  do?  \\nPCA finds a new set of dimensions (or a set of basis of views) such that all the dimensions are  \\northogonal (and hence linearly independent) and ranked according to the variance of data along  \\nthem. It means more important principle axis occurs first. (more important = more variance/more  \\nspread  out data)  \\n \\nHow  does  PCA  work?  \\n• Calculate  the covariance matrix  X of data  points.', metadata={'page': 1, 'source': '/content/pca_d1.pdf'}),\n",
              " Document(page_content='1  \\n N  \\n1 Principal  Component  Analysis  \\nIn real world data analysis tasks we analyze complex data i.e. multi dimensional data. We plot the  \\ndata and find various patterns in it or use it to train some machine learning models.  One way to  \\nthink  about  dimensions  is that  suppose  you have  an data  point  x , if we consider  this data  point  as \\na physical  object  then  dimensions  are merely  a basis  of view,  like where  is the data  located  when', metadata={'page': 0, 'source': '/content/pca_d1.pdf'}),\n",
              " Document(page_content='This defines  the goal  of PCA: - \\n1. Find  linearly  independent  dimensions  which  can losslessly  represent  the data  points.  \\n2. Those  newly  found  dimensions  should  allow  us to predict/reconstruct  the original  dimensions.', metadata={'page': 2, 'source': '/content/pca_d1.pdf'}),\n",
              " Document(page_content='• zero  values  as the off diagonal  elements.  \\nWe call it a diagonal matrix. So, we have to transform the original data points such that their  \\ncovariance  is a diagonal  matrix.  \\nAlways  normalize  your  data  before  doing  PCA if we use data  (features  here)  of different  scales,  we \\nget misleading components. We can also simply use correlation matrix instead of using covariance  \\nmatrix  if features  are of different  scales.  \\nThis defines  the goal  of PCA: -', metadata={'page': 2, 'source': '/content/pca_d1.pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Understanding RAG Prompt under the hood**"
      ],
      "metadata": {
        "id": "Y-ea4zDtRnYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "prompt"
      ],
      "metadata": {
        "id": "2USwNz7lRn0y",
        "outputId": "d2d2ba4f-dd3d-4802-aaa6-bb6ff398d509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use three sentences maximum. Keep the answer as concise as possible.\n",
        "\n",
        "In the following activity, we build a prompt template using the **PromptTemplate** class from the **langchain.prompts** module.\n",
        "\n",
        "**Functionality:**\n",
        "* Template Construction:\n",
        "The template string contains a customizable format for constructing prompts. It includes placeholders such as {context} and {question} that will be filled in with actual context and question data.\n",
        "* PromptTemplate Initialization: **PromptTemplate(input_variables=[\"context\", \"question\"], template=template)** initializes an instance of the PromptTemplate class with specified input variables and the template string.\n",
        "* **input_variables** specifies the variables that will be used to fill in the placeholders in the template.\n",
        "* **template** parameter contains the template string defining the structure of the prompt."
      ],
      "metadata": {
        "id": "BqGrJNIWLqks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build prompt\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)"
      ],
      "metadata": {
        "id": "tB6IsTdSLvgs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QA_CHAIN_PROMPT"
      ],
      "metadata": {
        "id": "IQasHvgTSX92",
        "outputId": "4c15d5ad-0be5-4eb9-d4ea-f3e677b216ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context', 'question'], template='Use the following pieces of context to answer the question at the end.\\nIf you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\nAlways say \"thanks for asking!\" at the end of the answer.\\n{context}\\nQuestion: {question}\\nHelpful Answer:')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the below code cell,\n",
        "* **llm:** It specifies the language model used for question answering.\n",
        "* **retriever:** It defines the document retrieval method, including search type and search parameters.\n",
        "\n",
        "    -- We configure the vectordb object to act as a retriever for similarity\n",
        "    search using Maximal Marginal Relevance (MMR) algorithm. It specifies to retrieve 2 top relevant documents and fetch 6 additional related documents for diversification.\n",
        "* **chain_type_kwargs:** It provides additional settings for the retrieval-based question answering chain, such as the prompt template.\n",
        "* **return_source_documents:** It determines whether the retrieved source documents are returned along with the answers."
      ],
      "metadata": {
        "id": "K8xz-tQn6eUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(llm,\n",
        "                                       retriever=vectordb.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 2, \"fetch_k\":6} ), # \"k\":2, \"fetch_k\":3\n",
        "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
        "                                       return_source_documents=True\n",
        "                                       )"
      ],
      "metadata": {
        "id": "-LJ3BqKjL89C"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain"
      ],
      "metadata": {
        "id": "ZTMm7LokcWdB",
        "outputId": "cb82ef3a-d0c0-48e0-dd83-41781bb650f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RetrievalQA(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template='Use the following pieces of context to answer the question at the end.\\nIf you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\nAlways say \"thanks for asking!\" at the end of the answer.\\n{context}\\nQuestion: {question}\\nHelpful Answer:'), llm=ChatHuggingFace(llm=HuggingFaceEndpoint(repo_id='HuggingFaceH4/zephyr-7b-beta', top_k=30, temperature=0.1, repetition_penalty=1.03, model='HuggingFaceH4/zephyr-7b-beta', client=<InferenceClient(model='HuggingFaceH4/zephyr-7b-beta', timeout=120)>, async_client=<InferenceClient(model='HuggingFaceH4/zephyr-7b-beta', timeout=120)>, task='text-generation'), tokenizer=LlamaTokenizerFast(name_or_path='HuggingFaceH4/zephyr-7b-beta', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='left', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>', 'additional_special_tokens': ['<unk>', '<s>', '</s>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}, model_id='HuggingFaceH4/zephyr-7b-beta')), document_variable_name='context'), return_source_documents=True, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceHubEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f5742d28580>, search_type='mmr', search_kwargs={'k': 2, 'fetch_k': 6}))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1**"
      ],
      "metadata": {
        "id": "SHn6k5ePZ2oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is principal component analysis?\"\n",
        "result = qa_chain.invoke({\"query\": question})\n",
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "id": "UGORZtkrMvx3",
        "outputId": "78e64579-42e5-4726-e1fa-2c85e9c569a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='2  \\n  \\nSo, what does  Principal  Component  Analysis  (PCA)  do?  \\nPCA finds a new set of dimensions (or a set of basis of views) such that all the dimensions are  \\northogonal (and hence linearly independent) and ranked according to the variance of data along  \\nthem. It means more important principle axis occurs first. (more important = more variance/more  \\nspread  out data)  \\n \\nHow  does  PCA  work?  \\n• Calculate  the covariance matrix  X of data  points.', metadata={'page': 1, 'source': '/content/pca_d1.pdf'}),\n",
              " Document(page_content='1  \\n N  \\n1 Principal  Component  Analysis  \\nIn real world data analysis tasks we analyze complex data i.e. multi dimensional data. We plot the  \\ndata and find various patterns in it or use it to train some machine learning models.  One way to  \\nthink  about  dimensions  is that  suppose  you have  an data  point  x , if we consider  this data  point  as \\na physical  object  then  dimensions  are merely  a basis  of view,  like where  is the data  located  when', metadata={'page': 0, 'source': '/content/pca_d1.pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "-FxSBsmdXtgz",
        "outputId": "9e7bb318-4222-44c1-9feb-7350ac888fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Principal Component Analysis (PCA) is a statistical technique that transforms a large set of variables into a smaller set of variables called principal components. These principal components are orthogonal and ordered by their variance, with the first principal component explaining the most variability in the data. PCA helps to simplify complex multidimensional data by reducing the number of dimensions required to represent it, making it easier to visualize and analyze. By finding a new set of dimensions that are orthogonal and ranked by variance, PCA allows us to identify the most important factors that contribute to the variability in the data. In summary, PCA is a powerful tool for data analysis that can help to reduce dimensionality, simplify data interpretation, and improve model accuracy. Thanks for asking!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2**"
      ],
      "metadata": {
        "id": "MV-VTth3Zq6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What does it say about variance in context of both PCA and Ensemble?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "id": "J1LmenL3ZNrV",
        "outputId": "c9568f40-783f-48d5-8b9b-aa630ae0e19e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='observation and vice versa. Boosting in general decreases the bias error and builds strong predictive  \\nmodels.  \\n \\nVariance  \\nVariance quantifies how the predictions made on same observation are different from each other. A  \\nhigh variance model will over -fit on your training population and perform badly on any observation  \\nbeyond  training.  Thus,  we aim at low variance.', metadata={'page': 0, 'source': '/content/ens_d2.pdf'}),\n",
              " Document(page_content='2  \\n  \\nSo, what does  Principal  Component  Analysis  (PCA)  do?  \\nPCA finds a new set of dimensions (or a set of basis of views) such that all the dimensions are  \\northogonal (and hence linearly independent) and ranked according to the variance of data along  \\nthem. It means more important principle axis occurs first. (more important = more variance/more  \\nspread  out data)  \\n \\nHow  does  PCA  work?  \\n• Calculate  the covariance matrix  X of data  points.', metadata={'page': 1, 'source': '/content/pca_d1.pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "i1w5C9OOZjEf",
        "outputId": "6a8904fe-5f06-4399-f6d0-28eaa9463004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the context of PCA, variance refers to the spread or dispersion of the data points around their mean. PCA aims to find a new set of dimensions that capture the maximum variance in the data, as this will result in a lower dimensional representation that still preserves most of the variability in the original data. This is achieved by finding the principal component axes, which are orthogonal to each other and ordered by their variance.\\n\\nIn the context of ensemble learning, variance also refers to the variability or uncertainty in the predictions made by individual models in the ensemble. A high variance ensemble will have widely varying predictions for the same input, which can lead to overfitting and poor generalization performance. To mitigate this, ensemble methods often use techniques such as bagging (bootstrap aggregating) or boosting to reduce the variance of the predictions by combining the outputs of multiple models. By doing so, they can achieve lower overall error and better generalization performance compared to using a single model.\\n\\nIn summary, while the concept of variance is related in both PCA and ensemble learning, it has different meanings in each context. In PCA, variance refers to the spread of the data points, while in ensemble learning, variance refers to the variability in the predictions made by individual models.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RetrievalQA chain types : [Map reduce, Refine, Map rerank (Legacy)](https://python.langchain.com/docs/modules/chains/)**\n",
        "\n",
        "- Whatever techniques we have used is stuff method (default - chain_type=\"stuff\") and there is only one call to LLM\n",
        "\n",
        "-- The **\"stuff\"** method, designated as the default chain type **(\"chain_type='stuff'\")**, typically refers to a basic approach where retrieved documents are directly processed by the Large Language Model (LLM) without employing specific strategies like **map reduce** or **reranking**.\n",
        "\n",
        "-- It implies a straightforward application of the LLM to generate answers based on the retrieved documents, without additional refinement or iterative processing.\n",
        "\n",
        "But, in the following approach, we will use the **Map Reduce**. The RetrievalQA chain types represent different strategies for combining retrieval and question-answering (QA) methods.\n",
        "1. **Map Reduce:**\n",
        "* In the Map Reduce strategy, documents are initially retrieved using a retrieval method such as MMR (Maximal Marginal Relevance).\n",
        "* The retrieved documents are then processed in parallel (mapped) to generate candidate answers using the QA model.\n",
        "* Finally, the candidate answers are reduced or combined to produce a final answer.\n",
        "2. **Refine:**\n",
        "* The Refine strategy involves an iterative process where retrieved documents are refined or filtered based on their relevance and other criteria.\n",
        "* After an initial retrieval step, the documents are further refined through multiple iterations, potentially incorporating user feedback or additional context.\n",
        "* This iterative refinement process aims to improve the quality and relevance of the retrieved documents and answers over time.\n",
        "3. **Map Rerank (Legacy):**\n",
        "* In the Map Rerank strategy, retrieved documents are first ranked based on their relevance to the query using a retrieval method.\n",
        "* The top-ranked documents are then reranked or reevaluated using the QA model to generate final answers.\n",
        "* This strategy focuses on refining the ranking of retrieved documents to prioritize the most relevant ones for generating answers."
      ],
      "metadata": {
        "id": "ksvPzTKHdjYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain_mr = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordb.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 4, \"fetch_k\":8}),\n",
        "    chain_type=\"map_reduce\"\n",
        ")"
      ],
      "metadata": {
        "id": "_gJGOi7vczPO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question =\"What principal component analysis?\"\n",
        "result = qa_chain_mr({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "ELbLfWWAdxOG",
        "outputId": "208bb012-0760-444b-9dbd-b3f8f1f3b0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "168dfd421eea407c9c7f1bfe2be3cfdb",
            "adf005e74ac04b2d83d2df0a62b70ff5",
            "b29424c42ab94fc8a6cad271a8d37126",
            "7dae1bf764ce447bb5ce4866414aa6b8",
            "cce7611142a94e29817d0617ae16f665",
            "507b8e2cb5dd4bc1ac565ddd69377f21",
            "b8941e11416e4f81b457aadd82dc96ad",
            "c17cb06e2407454cadd0dec084e2a9a1",
            "4d8b801ebcd74cbaa9d5084305b04de4",
            "c21d006e0e6c402cae4fb45927e43d06",
            "bb8b62791e0a41d0a6705bb398880031",
            "aa09140392c1424795ddab5c928773da",
            "1c5e4ced524e4e6684cadc8ea0b07a82",
            "ddbc8e63333a4595913a38296bb8a209",
            "877c7f7308e749548a03f9d9aaa856ff",
            "252d33ff9cf241439b1d561a5dcb082b",
            "7124d707f64347ef85d06c3ebdf65588",
            "eabf89b1a181408892e0575eee3300ec",
            "059d786237bd4922955e2b1859b61ef4",
            "eeb638e7de6944578aac2534e10e5c5a",
            "3d84a9e95c2e4fbbb7be9d1b2ad56786",
            "c7dd39aa66524b88b66ba192a6cbf56a",
            "7cb60f5a000542df8e769d81d344af09",
            "d5edcc5167484ed39510bd5446fe41c4",
            "00adbaea4c8141a69431d89f3910db2f",
            "8381713bacdd46d0bba2d23e8cee3e6c",
            "2881590b078449a2ab5b4c7752dc65b7",
            "c0f680f42bfc4a6da5d10fe7e806b7d9",
            "250bdc9acaab4cc4ad0bc08325c31125",
            "2eabf85e818247d08f9f4ef3d5e853b2",
            "af61a69ddf094c8881e0cd8161ed5aef",
            "ba12b8a42bf84bba88ba297fb0b6ed59",
            "f493159e719b41d69594c8466de58487",
            "d2a4a66e9b994a7f9d6746d0e6de8018",
            "0aff2f8421bf40c891306ade5bfe8fa7",
            "06b759ce975542d2a267afd3be9b1a94",
            "e8ee60a8e87b4e438ca37f9521cecbd6",
            "8506aa13ceb345518783bbca90b5826d",
            "ec88f1a00f1b4e53b708c526d4d1d6f5",
            "86701fec82b04f49b3a5868c376cd6f5",
            "33d7758e6124429c96208e0b972836b9",
            "9c02da4a954c4da5bbee1acf51dca6bb",
            "4c36ab6636d745bebc9006337dbfdec7",
            "5d900242ffc0435db248dfec5f57c2aa",
            "200f17dc2a3b41a7bc22a12c4dee0516",
            "7a46860a31ae435ca9d4d2de69615bb0",
            "c2b94e0068474f7bae36f68d7dbdd397",
            "0b70fceff53144e8a51e076db6ac9234",
            "88b3559a973548cda34622df3ee0acab",
            "fd7501eca90b41d0a0eac8325caf4aed",
            "2aba1148f4f54386b9078d275ca50e03",
            "fcf6c53ad2874f2f9e15ab3b8128a8bf",
            "8fafd6d9cd6a47ddb67920b8a0f0375b",
            "9fc2a9ae189d4de099f4aa1d5c3b5870",
            "6ad1e22dd3344880b3993b9e25cc02ec"
          ]
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "168dfd421eea407c9c7f1bfe2be3cfdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa09140392c1424795ddab5c928773da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cb60f5a000542df8e769d81d344af09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2a4a66e9b994a7f9d6746d0e6de8018"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "200f17dc2a3b41a7bc22a12c4dee0516"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Principal Component Analysis (PCA) is a statistical technique used to analyze and reduce the dimensionality of a large dataset by transforming it into a new set of variables called principal components. These components are linear combinations of the original variables and are ordered by their variance, with the first principal component explaining the most variability in the data. PCA is commonly used in data analysis and machine learning applications to simplify complex datasets, visualize data, and extract useful features for further analysis or modeling.\\n\\nIf you're asking whether we're specifically discussing PCA in this context, the answer is yes. The text provided explains what PCA is, how it works, and how it can be used to prepare data for further analysis.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Make it like Chatbot : Adding Memory**\n",
        "\n",
        "1. In the below approach, we use the ConversationBufferMemory which is the most straightforward conversational memory in LangChain. As per its functionality, the raw input of the past conversation between the human and AI is passed — in its raw form — to the {history} parameter.\n",
        "2. **ConversationBufferMemory** facilitates the storage and retrieval of conversation history, allowing systems to maintain context across multiple interactions.\n",
        "3. It stores messages exchanged during conversations, enabling systems to access past interactions for context-aware responses.\n",
        "4. **memory_key:** It specifies the key or identifier used to access the conversation history within the memory storage.\n",
        "5. **return_messages:** It determines whether the memory should return individual messages along with their associated metadata, such as timestamps or sender information. If set to **True**, messages will be returned; if set to **False**, only aggregate information about the conversation may be returned."
      ],
      "metadata": {
        "id": "7NbLm1boaRT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ngcffei9fHNm"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationalRetrievalChain** is a kind of chain used to be provided with a query and to answer it using documents retrieved from the query.\n",
        "\n",
        "It is one of the many possibilities to perform **Retrieval Augmented Generation (RAG)**.\n",
        "\n",
        "But it won’t only answer your last query, it will also use the chat history to improve the quality of the RAG by taking into account past queries and answers when:\n",
        "1. retrieving documents,\n",
        "2. feeding the LLM with those documents and asking it to answer a question.\n",
        "It basically works in 3 major steps:\n",
        "* **Step-1 (query rephrasing):** What you need to understand that the query that will be used is not always the one that you gave the chain, but one that will be constructing using your query and the conversation history, which allow the chain to “remember” what you are asking about. The conversational retrieval chain will for each question (except for the first) rephrase the query to take into account the chat history.\n",
        "* **Step-2 (relevant document retrieval):** In this step, the chain will use the provided ‘retriever’ to find document relevant to the question. A retriever is basically an object with a function taking a query and returning a list of documents.\n",
        "In most implementations, RAGs use a retriever constructed from a vectorstore (i.e., a vector database).\n",
        "* **Step-3 (the generation):** Context + Question = Answer.  In this step, we will basically ask the LLM to answer the rephrased question using the text from the found relevant documents."
      ],
      "metadata": {
        "id": "k1PD_GVWACIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run chain\n",
        "qa= ConversationalRetrievalChain.from_llm(llm,\n",
        "                                       retriever=vectordb.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 4, \"fetch_k\":8} ), # \"k\":2, \"fetch_k\":3\n",
        "                                       memory=memory\n",
        "                                       )"
      ],
      "metadata": {
        "id": "L994Ysxkff9S"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"tell me something about PCA\"\n",
        "result = qa.invoke({\"question\": question})"
      ],
      "metadata": {
        "id": "3jkbHJvXf9Ai"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer']"
      ],
      "metadata": {
        "id": "BHxC5yLRhLHL",
        "outputId": "01e1d0a1-cdd5-4a06-f699-e14c52ba7b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Principal Component Analysis (PCA) is a statistical technique used to analyze and reduce the dimensionality of a large dataset. It finds a new set of dimensions or basis views that are orthogonal (linearly independent) and ranked based on the variance of the data along them. The goal of PCA is to find linearly independent dimensions that can losslessly represent the data points and allow us to predict or reconstruct the original dimensions. PCA helps to remove correlated dimensions by making the covariance matrix have large numbers as the main diagonal elements and zero values as the off-diagonal elements. This ensures that the data is spread out along the dimensions with high variance and the dimensions are linearly independent. Normalizing the data before doing PCA is recommended if the features have different scales to avoid misleading components. Overall, PCA is a powerful tool for data analysis and dimensionality reduction in various fields such as finance, engineering, and science.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"please list point-wise,  how does pca works?\"\n",
        "result = qa({\"question\": question})"
      ],
      "metadata": {
        "id": "dN3atqo6hfc4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['answer'])"
      ],
      "metadata": {
        "id": "2Z7pSOdThii4",
        "outputId": "d226fa39-b568-4665-f565-0e4882fef85d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Principal Component Analysis (PCA) is a statistical technique used to analyze and reduce the dimensionality of a large dataset. It works by finding a new set of orthogonal dimensions, called principal components, that explain the maximum variance in the data. These principal components are ordered by their variance, with the first component explaining the most variance and subsequent components explaining less.\n",
            "\n",
            "Here's a step-by-step explanation of how PCA works:\n",
            "\n",
            "1. Data Preprocessing: Before applying PCA, it's essential to preprocess the data. This involves normalizing the data to have zero mean and unit variance. This step ensures that all features have equal importance in the analysis and prevents the algorithm from being dominated by features with larger scales.\n",
            "\n",
            "2. Covariance Matrix Calculation: The next step is to calculate the covariance matrix of the preprocessed data. The covariance matrix represents the pairwise relationships between the features.\n",
            "\n",
            "3. Eigenvalue and Eigenvector Calculation: The eigenvalues and eigenvectors of the covariance matrix are calculated. Eigenvalues represent the variance explained by each principal component, while eigenvectors represent the direction of the principal component.\n",
            "\n",
            "4. Sorting Eigenvectors: The eigenvectors are sorted based on their corresponding eigenvalues in descending order. This step ensures that the most important principal components are selected first.\n",
            "\n",
            "5. Principal Component Selection: The first k eigenvectors, where k is the desired number of principal components, are selected. These eigenvectors represent the new set of orthogonal dimensions that explain the maximum variance in the data.\n",
            "\n",
            "6. Data Transformation: The original data is transformed into the new set of principal components. This step reduces the dimensionality of the data and makes it easier to visualize and analyze.\n",
            "\n",
            "7. Reconstruction: The original data can be reconstructed from the transformed data by projecting it back onto the original feature space. This step ensures that the transformed data accurately represents the original data.\n",
            "\n",
            "In summary, PCA works by finding a new set of orthogonal dimensions that explain the maximum variance in the data. It involves preprocessing the data, calculating the covariance matrix, calculating eigenvalues and eigenvectors, sorting the eigenvectors, selecting the principal components, transforming the data, and reconstructing the original data. PCA is a powerful statistical technique that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"what do we get from covariance matrix for doing PCA?\"\n",
        "result = qa({\"question\": question})\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "id": "rH_Z97sJiWLb",
        "outputId": "4ac9ceb7-951e-43b3-97de-7be8748f2979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The covariance matrix plays a crucial role in performing Principal Component Analysis (PCA). In PCA, we aim to find a new set of dimensions or a set of basis views that are orthogonal and ranked according to the variance of the data along them. The covariance matrix helps us calculate the variance and covariance of the data points along each dimension. By calculating the covariance matrix, we can identify the dimensions with high variance and covariance, which indicates that they contain most of the information in the data. We then replace these dimensions with linear combinations of the related n dimensions to reduce the dimensionality of the data while preserving most of the variance. This process helps us to identify the underlying structure and patterns in the data more clearly and efficiently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download the vector DB**"
      ],
      "metadata": {
        "id": "GHJ1ujNcuFNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the entire folder\n",
        "!zip -r /content/docs.zip /content/docs"
      ],
      "metadata": {
        "id": "Defg2TBIuIeB",
        "outputId": "3422035c-0734-40eb-8b34-16ba1138ba35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/docs/ (stored 0%)\n",
            "  adding: content/docs/chroma/ (stored 0%)\n",
            "  adding: content/docs/chroma/9992ae92-f624-4fee-bb5e-d6806febba95/ (stored 0%)\n",
            "  adding: content/docs/chroma/9992ae92-f624-4fee-bb5e-d6806febba95/header.bin (deflated 61%)\n",
            "  adding: content/docs/chroma/9992ae92-f624-4fee-bb5e-d6806febba95/length.bin (deflated 19%)\n",
            "  adding: content/docs/chroma/9992ae92-f624-4fee-bb5e-d6806febba95/link_lists.bin (stored 0%)\n",
            "  adding: content/docs/chroma/9992ae92-f624-4fee-bb5e-d6806febba95/data_level0.bin (deflated 100%)\n",
            "  adding: content/docs/chroma/chroma.sqlite3 (deflated 69%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"/content/docs.zip\")"
      ],
      "metadata": {
        "id": "wm3nYLKJuKYq",
        "outputId": "1ce24a65-4629-42e6-a3b0-66ee27b78a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0df3e704-ec7f-465d-b49b-62aec54075c4\", \"docs.zip\", 117548)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Upload the vector db from previous step and unzip**"
      ],
      "metadata": {
        "id": "BMa6GdcUuXcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/docs.zip  -d /"
      ],
      "metadata": {
        "id": "VXn0d0k6ubPm",
        "outputId": "ed88babb-308e-4630-9eb7-f10cc3522a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/docs.zip\n",
            "replace /content/docs/chroma/9992ae92-f624-4fee-bb5e-d6806febba95/header.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lpgSGCOwMdEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Contextual Compression Retriever has 2 major components which are { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"All of the above\" #@param [\"\", \"embedding and vectordb\", \"map and reduce\", \"RecursiveCharacterTextSplitter and Document loader\", \"a base retriever and a Document Compressor\", \"All of the above\"]"
      ],
      "metadata": {
        "id": "1EO4jyE-MhMa"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Too Difficult for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]"
      ],
      "metadata": {
        "id": "MsW4GoJ3MlPq"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"I will need more homework to grasp these topics\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "i5yQ2kN5MqDh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]"
      ],
      "metadata": {
        "id": "FdrvAECvMuWZ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"
      ],
      "metadata": {
        "id": "ozkCFVh5MyAE"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"
      ],
      "metadata": {
        "id": "WEeJT0rrNGNh"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YDK5_-9UNKaq",
        "outputId": "fc2947a0-72bf-4373-81a8-3df889a1bd08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 5443\n",
            "Date of submission:  21 May 2024\n",
            "Time of submission:  15:48:11\n",
            "View your submissions: https://cds-iisc.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}